{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbef2679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from kymatio.torch import Scattering2D\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c663285",
   "metadata": {},
   "source": [
    "# Some Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3844502",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pkl(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "def fftshift2d(x, ifft=False):\n",
    "    assert (len(x.shape) == 2) and all([(s % 2 == 1) for s in x.shape])\n",
    "    s0 = (x.shape[0] // 2) + (0 if ifft else 1)\n",
    "    s1 = (x.shape[1] // 2) + (0 if ifft else 1)\n",
    "    x = np.concatenate([x[s0:, :], x[:s0, :]], axis=0)\n",
    "    x = np.concatenate([x[:, s1:], x[:, :s1]], axis=1)\n",
    "    return x\n",
    "def fftshift3d(x, ifft):\n",
    "    assert len(x.shape) == 4\n",
    "    s0 = (x.shape[2] // 2) + (0 if ifft else 1)\n",
    "    s1 = (x.shape[3] // 2) + (0 if ifft else 1)\n",
    "    x = torch.cat([x[:,:, s0:, :], x[:,:, :s0, :]], dim=2)\n",
    "    x = torch.cat([x[:,:, :, s1:], x[:,:, :, :s1]], dim=3)\n",
    "    return x\n",
    "\n",
    "def get_reduced_dataset(images, specs, fraction, datasetclass):\n",
    "    n_total=len(images)\n",
    "    n_subset=int(n_total*fraction)\n",
    "    indices=np.random.choice(n_total,n_subset,replace=False)\n",
    "    subset_images = images[indices]\n",
    "    subset_specs = specs[indices]\n",
    "    return datasetclass(subset_images, subset_specs)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b357c353",
   "metadata": {},
   "source": [
    "## Loading Datasets obtained via the n2n preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0037d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = \"C:/Users/javit/Desktop/N2N/datasets/ixi_train.pkl\"\n",
    "ruta_test = \"C:/Users/javit/Desktop/N2N/datasets/ixi_valid.pkl\"\n",
    "img, spec = load_pkl(ruta)\n",
    "img=img[:,:-1,:-1] #images are now 255,255\n",
    "img = img.astype(np.float32) / 255.0 - 0.5 # normalize and make sure they are in range [-.5,.5]\n",
    "test_img, test_spec = load_pkl(ruta_test)\n",
    "test_img=test_img[:,:-1,:-1]\n",
    "test_img=test_img.astype(np.float32) / 255.0 - 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f718103f",
   "metadata": {},
   "source": [
    "## Bernoulli masking corruption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2910c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_at_edge=0.025\n",
    "h = [s // 2 for s in (255,255)] #255\n",
    "r = [np.arange(s, dtype=np.float32) - h for s, h in zip((255,255), h)]\n",
    "r = [x ** 2 for x in r]\n",
    "r = (r[0][:, np.newaxis] + r[1][np.newaxis, :]) ** .5\n",
    "m = (p_at_edge ** (1./h[1])) ** r\n",
    "bern_mask = m\n",
    "\n",
    "def corrupt_data_binary(img, spec):\n",
    "    global bern_mask\n",
    "    mask = bern_mask\n",
    "    # print('Bernoulli probability at edge = %.5f' % mask[h[0], 0])\n",
    "    # print('Average Bernoulli probability = %.5f' % np.mean(mask))\n",
    "    keep = (np.random.uniform(0.0, 1.0, size=spec.shape)**2 < mask)\n",
    "    keep = keep & keep[::-1, ::-1]\n",
    "    sval = spec * keep\n",
    "    smsk = keep.astype(np.float32)\n",
    "    spec = fftshift2d(sval / (mask + ~keep), ifft=True) # Add 1.0 to not-kept values to prevent div-by-zero.\n",
    "    img = np.real(np.fft.ifft2(spec)).astype(np.float32)\n",
    "    return img, sval, smsk\n",
    "\n",
    "class BinaryDenoisingDataset(Dataset):\n",
    "    def __init__(self,clean_images,clean_specs,corrupt_fn=corrupt_data_binary):\n",
    "        super(BinaryDenoisingDataset, self).__init__()\n",
    "        self.clean_images = clean_images\n",
    "        self.clean_specs = clean_specs\n",
    "        self.corrupt_fn = corrupt_fn\n",
    "    def __len__(self):\n",
    "        return len(self.clean_images)\n",
    "    def __getitem__(self, idx):\n",
    "        img_clean= self.clean_images[idx]\n",
    "        spec_clean = self.clean_specs[idx]\n",
    "        # Corrupt data\n",
    "        cimg, cspec, cmask = self.corrupt_fn(img_clean,spec_clean)\n",
    "        img_noisy = torch.tensor(cimg,dtype=torch.float32)\n",
    "        spec_noisy = torch.tensor(cspec,dtype=torch.complex64)\n",
    "        mask = torch.tensor(cmask,dtype=torch.float32)\n",
    "        img_clean = torch.tensor(img_clean,dtype=torch.float32)\n",
    "        spec_clean = torch.tensor(spec_clean,dtype=torch.complex64)\n",
    "        return img_clean.unsqueeze(0), spec_clean.unsqueeze(0), img_noisy.unsqueeze(0), spec_noisy.unsqueeze(0), mask.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f1fe21",
   "metadata": {},
   "source": [
    "## Rician Noise Corruption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8b1f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt_data_rician(img,noise_percent):\n",
    "    sigma =(noise_percent/100)*img.max().item()\n",
    "    noise1 = np.random.normal(0,sigma,img.shape)\n",
    "    noise2 = np.random.normal(0,sigma,img.shape)\n",
    "    noisy_img = np.sqrt((img+noise1)**2+noise2**2)\n",
    "    return noisy_img\n",
    "class RicianDenoisingDataset(Dataset):\n",
    "    def __init__(self,clean_images,t=64,corrupt_fn=corrupt_data_rician,augment_fn=None):\n",
    "        super(RicianDenoisingDataset, self).__init__()\n",
    "        self.clean_images = clean_images\n",
    "        self.t = t\n",
    "        self.corrupt_fn = corrupt_fn\n",
    "        self.augment_fn = augment_fn\n",
    "    def __len__(self):\n",
    "        return len(self.clean_images)\n",
    "    def __getitem__(self, idx):\n",
    "        img_clean= self.clean_images[idx]+0.5 #now img in[0,1] range\n",
    "        # Data augmentation\n",
    "        if self.augment_fn:\n",
    "            img_clean,spec_clean = self.augment_fn(img_clean,spec_clean,t=self.t)        \n",
    "        # Corrupt data\n",
    "        cimg = self.corrupt_fn(img_clean,11)\n",
    "        img_noisy = torch.tensor(cimg,dtype=torch.float32).clamp(0,1)\n",
    "        img_clean = torch.tensor(img_clean,dtype=torch.float32).clamp(0,1)\n",
    "        return img_clean.unsqueeze(0)-0.5, img_noisy.unsqueeze(0)-0.5 #Again in [-.5,.5] range"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a434bc5",
   "metadata": {},
   "source": [
    "# Model Definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "687ea11f",
   "metadata": {},
   "source": [
    "## UNet architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f71ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Unet, self).__init__()\n",
    "\n",
    "        #Encoder\n",
    "        self.conv0 = nn.Conv2d(1, 48, 3, stride=1, padding=1)\n",
    "        self.conv1 = nn.Conv2d(48, 48, 3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(48, 48, 3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(48, 48, 3, stride=1, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(48, 48, 3, stride=1, padding=1)\n",
    "        self.pool4 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(48, 48, 3, stride=1, padding=1)\n",
    "        self.pool5 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv6 = nn.Conv2d(48, 48, 3, stride=1, padding=1)\n",
    "\n",
    "        #Decoder\n",
    "        self.upsample5 = nn.Upsample(scale_factor=2)\n",
    "        self.deconv5a = nn.Conv2d(96, 96, 3, stride=1, padding=1)\n",
    "        self.deconv5b = nn.Conv2d(96, 96, 3, stride=1, padding=1)\n",
    "\n",
    "        self.upsample4 = nn.Upsample(scale_factor=2)\n",
    "        self.deconv4a = nn.Conv2d(144, 96, 3, stride=1, padding=1)\n",
    "        self.deconv4b = nn.Conv2d(96, 96, 3, stride=1, padding=1)\n",
    "\n",
    "        self.upsample3 = nn.Upsample(scale_factor=2)\n",
    "        self.deconv3a = nn.Conv2d(144, 96, 3, stride=1, padding=1)\n",
    "        self.deconv3b = nn.Conv2d(96, 96, 3, stride=1, padding=1)\n",
    "\n",
    "        self.upsample2 = nn.Upsample(scale_factor=2)\n",
    "        self.deconv2a = nn.Conv2d(144, 96, 3, stride=1, padding=1)\n",
    "        self.deconv2b = nn.Conv2d(96, 96, 3, stride=1, padding=1)\n",
    "\n",
    "        self.upsample1 = nn.Upsample(scale_factor=2)\n",
    "        self.deconv1a = nn.Conv2d(97, 64, 3, stride=1, padding=1)\n",
    "        self.deconv1b = nn.Conv2d(64, 32, 3, stride=1, padding=1)\n",
    "        self.deconv1c = nn.Conv2d(32, 1, 3, stride=1, padding=1)\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        original_in = F.pad(x, (0,1,0,1), mode='constant', value=-0.5)\n",
    "        x = F.leaky_relu(self.conv0(original_in))\n",
    "        x = F.leaky_relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        pool1 = x\n",
    "        x = F.leaky_relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        pool2 = x\n",
    "        x = F.leaky_relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        pool3 = x\n",
    "        x = F.leaky_relu(self.conv4(x))\n",
    "        x = self.pool4(x)\n",
    "        pool4 = x\n",
    "        x = F.leaky_relu(self.conv5(x))\n",
    "        x = self.pool5(x)\n",
    "        x = F.leaky_relu(self.conv6(x))\n",
    "        x = self.upsample5(x)\n",
    "        x = torch.cat((x, pool4), 1)\n",
    "        x = F.leaky_relu(self.deconv5a(x))\n",
    "        x = F.leaky_relu(self.deconv5b(x))\n",
    "        x = self.upsample4(x)\n",
    "        x = torch.cat((x, pool3), 1)\n",
    "        x = F.leaky_relu(self.deconv4a(x))\n",
    "        x = F.leaky_relu(self.deconv4b(x))\n",
    "        x = self.upsample3(x)\n",
    "        x = torch.cat((x, pool2), 1)\n",
    "        x = F.leaky_relu(self.deconv3a(x))\n",
    "        x = F.leaky_relu(self.deconv3b(x))\n",
    "        x = self.upsample2(x)\n",
    "        x = torch.cat((x, pool1), 1)\n",
    "        x = F.leaky_relu(self.deconv2a(x))\n",
    "        x = F.leaky_relu(self.deconv2b(x))\n",
    "        x = self.upsample1(x)\n",
    "        x = torch.cat((x, original_in), 1)\n",
    "        x = F.leaky_relu(self.deconv1a(x))\n",
    "        x = F.leaky_relu(self.deconv1b(x))\n",
    "        x = self.deconv1c(x)\n",
    "        return x[:,:,:-1,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86de3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Unet().to(device)\n",
    "summary(model, (1, 255, 255))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4584de9f",
   "metadata": {},
   "source": [
    "## CNNDMRI architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e943164",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNDMRI(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNDMRI, self).__init__()\n",
    "\n",
    "        #Initial convolutions\n",
    "        self.conv1 = nn.Conv2d(1,64,kernel_size=3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(64,64,kernel_size=3,padding=1)\n",
    "\n",
    "        # Encoder layers\n",
    "        self.enc1 = nn.Conv2d(64, 128, kernel_size=3, padding=1, stride=2)\n",
    "        self.enc2 = nn.Conv2d(128, 128, kernel_size=3, padding=1, stride=2)\n",
    "\n",
    "        #Residual blocks\n",
    "        self.res1conv1 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.res1conv2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.res2conv1 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.res2conv2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.res3conv1 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.res3conv2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "        self.res4conv1 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn7 = nn.BatchNorm2d(128)\n",
    "        self.res4conv2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn8 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # Decoder layers\n",
    "        self.dec1 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2,padding=1,output_padding=1)\n",
    "        self.dec2 = nn.ConvTranspose2d(64, 64, kernel_size=3, stride=2,padding=1)\n",
    "\n",
    "        #Final convolution\n",
    "        self.out = nn.Conv2d(64, 1, kernel_size=3, padding=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        original_noisy = x\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        #Encoder\n",
    "        x = F.relu(self.enc1(x))\n",
    "        x = F.relu(self.enc2(x))\n",
    "        #Residual blocks\n",
    "        res1 = x\n",
    "        x = self.res1conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.res1conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x += res1\n",
    "\n",
    "        res2 = x\n",
    "        x = self.res2conv1(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.res2conv2(x)\n",
    "        x = self.bn4(x)\n",
    "        x += res2\n",
    "\n",
    "        res3 = x\n",
    "        x = self.res3conv1(x)\n",
    "        x = F.relu(self.bn5(x))\n",
    "        x = self.res3conv2(x)\n",
    "        x = self.bn6(x)\n",
    "        x += res3\n",
    "\n",
    "        res4 = x\n",
    "        x = self.res4conv1(x)\n",
    "        x = F.relu(self.bn7(x))\n",
    "        x = self.res4conv2(x)\n",
    "        x = self.bn8(x)\n",
    "        x += res4\n",
    "        # Decoder\n",
    "        x = F.relu(self.dec1(x))\n",
    "        x = F.relu(self.dec2(x))\n",
    "        #Final convolution\n",
    "        x = self.out(x)\n",
    "        x += original_noisy\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc99d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNNDMRI().to(device)\n",
    "summary(model, (1, 255, 255))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43dbf7c7",
   "metadata": {},
   "source": [
    "## WST autoencoder architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac89959",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WSTAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WSTAutoencoder, self).__init__()\n",
    "        self.scattering2d = Scattering2D(J=2, L=8, shape=(256,256)) # [81,64,64]\n",
    "\n",
    "        #Decoder\n",
    "        self.conv0 = nn.Conv2d(81,64,3,stride=1,padding=1)\n",
    "        self.bn0 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.res1conv1 = nn.Conv2d(64,64,3,stride=1,padding=1)\n",
    "        self.res1bn1 = nn.BatchNorm2d(64)\n",
    "        self.res1conv2 = nn.Conv2d(64,64,3,stride=1,padding=1)\n",
    "        self.res1bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.res2conv1 = nn.Conv2d(64,64,3,stride=1,padding=1)\n",
    "        self.res2bn1 = nn.BatchNorm2d(64)\n",
    "        self.res2conv2 = nn.Conv2d(64,64,3,stride=1,padding=1)\n",
    "        self.res2bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.upsample1 = nn.Upsample(scale_factor=2) #[64,128,128]\n",
    "        self.conv1 = nn.Conv2d(64,32,3,stride=1,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.res3conv1 = nn.Conv2d(32,32,3,stride=1,padding=1)\n",
    "        self.res3bn1 = nn.BatchNorm2d(32)\n",
    "        self.res3conv2 = nn.Conv2d(32,32,3,stride=1,padding=1)\n",
    "        self.res3bn2 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.upsample2 = nn.Upsample(scale_factor=2) #[32,256,256]\n",
    "        self.conv2 = nn.Conv2d(33,16,3,stride=1,padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "\n",
    "        self.res4conv1 = nn.Conv2d(16,16,3,stride=1,padding=1)\n",
    "        self.res4bn1 = nn.BatchNorm2d(16)\n",
    "        self.res4conv2 = nn.Conv2d(16,16,3,stride=1,padding=1)\n",
    "        self.res4bn2 = nn.BatchNorm2d(16)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(16,9,3,stride=1,padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(9)\n",
    "\n",
    "        self.res5conv1 = nn.Conv2d(9,9,3,stride=1,padding=1)\n",
    "        self.res5bn1 = nn.BatchNorm2d(9)\n",
    "        self.res5conv2 = nn.Conv2d(9,9,3,stride=1,padding=1)\n",
    "        self.res5bn2 = nn.BatchNorm2d(9)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(9,1,3,stride=1,padding=1)\n",
    "        # self.bn4 = nn.BatchNorm2d(1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        original_in = F.pad(x, (0,1,0,1), mode='constant', value=-0.5)\n",
    "        x = self.scattering2d(original_in).squeeze(1)\n",
    "        \n",
    "        x = self.conv0(x)\n",
    "        x = F.leaky_relu(self.bn0(x))\n",
    "\n",
    "        resblock1_input =x\n",
    "        x = self.res1conv1(x)\n",
    "        x = F.leaky_relu(self.res1bn1(x))\n",
    "\n",
    "        x = self.res1conv2(x)\n",
    "        x = F.leaky_relu(self.res1bn2(x))\n",
    "\n",
    "        x = x + resblock1_input\n",
    "        resblock2_input = x\n",
    "        x = self.res2conv1(x)\n",
    "\n",
    "        x = self.res2conv2(x)\n",
    "        x = F.leaky_relu(self.res2bn2(x))\n",
    "\n",
    "        x = x + resblock2_input\n",
    "        x = self.upsample1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = F.leaky_relu(self.bn1(x))\n",
    "\n",
    "        resblock3_input = x\n",
    "        x = self.res3conv1(x)\n",
    "        x = F.leaky_relu(self.res3bn1(x))\n",
    "\n",
    "        x = self.res3conv2(x)\n",
    "        x = F.leaky_relu(self.res3bn2(x))\n",
    "        x = x + resblock3_input\n",
    "\n",
    "        x = self.upsample2(x)\n",
    "        x = torch.cat((x, original_in), dim=1)\n",
    "        x = self.conv2(x)\n",
    "        x = F.leaky_relu(self.bn2(x))\n",
    "\n",
    "        resblock4_input = x\n",
    "        x = self.res4conv1(x)\n",
    "        x = F.leaky_relu(self.res4bn1(x))\n",
    "        x = self.res4conv2(x)\n",
    "        x = F.leaky_relu(self.res4bn2(x))\n",
    "        x = x + resblock4_input\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = F.leaky_relu(self.bn3(x))\n",
    "\n",
    "        resblock5_input = x\n",
    "        x = self.res5conv1(x)\n",
    "        x = F.leaky_relu(self.res5bn1(x))\n",
    "        x = self.res5conv2(x)\n",
    "        x = F.leaky_relu(self.res5bn2(x))\n",
    "        x = x + resblock5_input\n",
    "        x = self.conv4(x)\n",
    "        # x = F.sigmoid(x)-0.5\n",
    "        return x[:,:,:-1,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30315921",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = WSTAutoencoder().to(device)\n",
    "summary(model, (1, 255, 255))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a15fc8e",
   "metadata": {},
   "source": [
    "# Binary mask denoising"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e6d218",
   "metadata": {},
   "source": [
    "## Load Dataset and Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e5925f",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_dataset= BinaryDenoisingDataset(img,spec)\n",
    "binary_test_dataset = BinaryDenoisingDataset(test_img,test_spec)\n",
    "binary_dataloader = DataLoader(binary_dataset, batch_size=32, shuffle=True)\n",
    "binary_dataloader_test = DataLoader(binary_test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d7347a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_train(net, trainLoader,testLoader, loss_fn, optimizer, scheduler, NUM_EPOCHS):\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        net.train()\n",
    "        running_loss = 0.0\n",
    "        with tqdm(trainLoader, unit=\"batch\") as tepoch:\n",
    "            for data in tepoch:\n",
    "                tepoch.set_description(f\"Epoch {epoch+1}\")\n",
    "                img_clean,spec_clean, img_noisy, spec_noisy, mask = data\n",
    "                img_noisy = img_noisy.to(device)\n",
    "                img_clean = img_clean.to(device)\n",
    "                spec_noisy = spec_noisy.to(device)\n",
    "                mask = mask.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                denoised = net(img_noisy)\n",
    "                denoised_spec = torch.fft.fft2(denoised)\n",
    "                denoised_spec = fftshift3d(denoised_spec, ifft=False)\n",
    "                spec_mask = mask.type(torch.complex64)\n",
    "                denoised_spec = spec_noisy * spec_mask + denoised_spec * (1 - spec_mask)\n",
    "                outputs = torch.real(torch.fft.ifft2(fftshift3d(denoised_spec, ifft=True)))\n",
    "                loss = loss_fn(outputs, img_clean)\n",
    "                # backpropagation\n",
    "                loss.backward()\n",
    "                # update the parameters\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                tepoch.set_postfix(loss=loss)    \n",
    "            \n",
    "            loss = running_loss / len(trainLoader)\n",
    "            train_loss.append(loss)\n",
    "        scheduler.step()\n",
    "        net.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            with tqdm(testLoader, unit=\"batch\") as tepoch:\n",
    "                for data in tepoch:\n",
    "                    img_clean,spec_clean, img_noisy, spec_noisy, mask = data\n",
    "                    img_noisy = img_noisy.to(device)\n",
    "                    img_clean = img_clean.to(device)\n",
    "                    spec_noisy = spec_noisy.to(device)\n",
    "                    mask = mask.to(device)\n",
    "                    denoised = net(img_noisy)\n",
    "                    denoised_spec = torch.fft.fft2(denoised)\n",
    "                    denoised_spec = fftshift3d(denoised_spec, ifft=False)\n",
    "                    spec_mask = mask.type(torch.complex64)\n",
    "                    denoised_spec = spec_noisy * spec_mask + denoised_spec * (1 - spec_mask)\n",
    "                    outputs = torch.real(torch.fft.ifft2(fftshift3d(denoised_spec, ifft=True)))\n",
    "                    outputs = torch.clamp(outputs, -.5, .5)\n",
    "                    loss = loss_fn(outputs, img_clean)\n",
    "                    val_loss += loss.item()\n",
    "                    tepoch.set_postfix(loss=loss)    \n",
    "                \n",
    "                loss = val_loss / len(testLoader)\n",
    "                test_loss.append(loss)\n",
    "        \n",
    "    \n",
    "    return train_loss,test_loss                          \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee81429",
   "metadata": {},
   "source": [
    "## Unet Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c3bbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "binaryunet = Unet().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(binaryunet.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "binary_unet_train_loss,binary_unet_test_loss = binary_train(binaryunet, binary_dataloader, binary_dataloader_test, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_binary_unet_with_freq_enh.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(binary_unet_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(binary_unet_train_loss, label='train loss')\n",
    "plt.plot(binary_unet_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ade309",
   "metadata": {},
   "source": [
    "## CNNDMRI train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab1bec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "binarycnndmri = CNNDMRI().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(binarycnndmri.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "binary_cnndmri_train_loss,binary_cnndmri_test_loss = binary_train(binarycnndmri, binary_dataloader, binary_dataloader_test, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_binary_cnndmri_with_freq_enh.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(binary_cnndmri_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(binary_cnndmri_train_loss, label='train loss')\n",
    "plt.plot(binary_cnndmri_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae675c38",
   "metadata": {},
   "source": [
    "## WSTAutoencoder train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb0efbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "binarywsta = WSTAutoencoder().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(binarywsta.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "binary_wsta_train_loss,binary_wsta_test_loss = binary_train(binarywsta, binary_dataloader, binary_dataloader_test, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_binary_wsta_with_freq_enh.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(binary_wsta_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(binary_wsta_train_loss, label='train loss')\n",
    "plt.plot(binary_wsta_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e55fa0",
   "metadata": {},
   "source": [
    "## Three models comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c57a699",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(binary_wsta_train_loss, label='WSTA architecture')\n",
    "plt.plot(binary_unet_train_loss, label='UNet architecture')\n",
    "plt.plot(binary_cnndmri_train_loss, label='CNNDMRI architecture')\n",
    "plt.title('Model comparison')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2268ee4e",
   "metadata": {},
   "source": [
    "# Rician Noise Denoising"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31c449a",
   "metadata": {},
   "source": [
    "## Dataset and train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a986e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rici_dataset = RicianDenoisingDataset(img,spec)\n",
    "rici_test_dataset = RicianDenoisingDataset(test_img,test_spec)\n",
    "rici_dataloader = DataLoader(rici_dataset, batch_size=32, shuffle=True)\n",
    "rici_dataloader_test = DataLoader(rici_test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0ed91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ricitrain(net, trainLoader,testLoader, loss_fn, optimizer, scheduler, NUM_EPOCHS):\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        net.train()\n",
    "        running_loss = 0.0\n",
    "        with tqdm(trainLoader, unit=\"batch\") as tepoch:\n",
    "            for data in tepoch:\n",
    "                tepoch.set_description(f\"Epoch {epoch+1}\")\n",
    "                img_clean, img_noisy = data\n",
    "                img_noisy = img_noisy.to(device)\n",
    "                img_clean = img_clean.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(img_noisy)\n",
    "                loss = loss_fn(outputs, img_clean)\n",
    "                # backpropagation\n",
    "                loss.backward()\n",
    "                # update the parameters\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                tepoch.set_postfix(loss=loss)    \n",
    "            \n",
    "            loss = running_loss / len(trainLoader)\n",
    "            train_loss.append(loss)\n",
    "        scheduler.step()\n",
    "        net.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            with tqdm(testLoader, unit=\"batch\") as tepoch:\n",
    "                for data in tepoch:\n",
    "                    img_clean, img_noisy= data\n",
    "                    img_noisy = img_noisy.to(device)\n",
    "                    img_clean = img_clean.to(device)\n",
    "                    outputs = net(img_noisy)\n",
    "                    outputs = torch.clamp(outputs, -.5, .5)\n",
    "                    loss = loss_fn(outputs, img_clean)\n",
    "                    val_loss += loss.item()\n",
    "                    tepoch.set_postfix(loss=loss)    \n",
    "                \n",
    "                loss = val_loss / len(testLoader)\n",
    "                test_loss.append(loss)\n",
    "        \n",
    "    \n",
    "    return train_loss,test_loss         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29990f02",
   "metadata": {},
   "source": [
    "## Unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7d8cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "ricianunet = Unet().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(ricianunet.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "rici_unet_train_loss,rici_unet_test_loss = ricitrain(ricianunet, rici_dataloader, rici_dataloader_test, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_rician_unet_complete.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(rici_unet_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(rici_unet_train_loss, label='train loss')\n",
    "plt.plot(rici_unet_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fafe849",
   "metadata": {},
   "source": [
    "## CNNDMRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf7f9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "ricicnndmri = CNNDMRI().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(ricicnndmri.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "rici_cnndmri_train_loss,rici_cnndmri_test_loss = ricitrain(ricicnndmri, rici_dataloader, rici_dataloader_test, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_rician_cnndmri_complete.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(rici_cnndmri_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(rici_cnndmri_train_loss, label='train loss')\n",
    "plt.plot(rici_cnndmri_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5959d254",
   "metadata": {},
   "source": [
    "## WSTAutoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dc7d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "riciwsta = WSTAutoencoder().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(riciwsta.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "rici_wsta_train_loss,rici_wsta_test_loss = ricitrain(riciwsta, rici_dataloader, rici_dataloader_test, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_rician_wsta_complete.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(rici_wsta_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(rici_wsta_train_loss, label='train loss')\n",
    "plt.plot(rici_wsta_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e00c9d4",
   "metadata": {},
   "source": [
    "## Three model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ea5548",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(rici_wsta_train_loss, label='WSTA architecture')\n",
    "plt.plot(rici_unet_train_loss, label='UNet architecture')\n",
    "plt.plot(rici_cnndmri_train_loss, label='CNNDMRI architecture')\n",
    "plt.title('Model comparison')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ffc96d",
   "metadata": {},
   "source": [
    "# Now lets test with reduced datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9b0709",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_dataset_75 = get_reduced_dataset(img,spec,0.75,BinaryDenoisingDataset)\n",
    "binary_test_dataset_75 = get_reduced_dataset(test_img,test_spec,0.75,BinaryDenoisingDataset)\n",
    "binary_dataloader_75 = DataLoader(binary_dataset_75, batch_size=32, shuffle=True)\n",
    "binary_dataloader_test_75 = DataLoader(binary_test_dataset_75, batch_size=32, shuffle=False)\n",
    "\n",
    "binary_dataset_50 = get_reduced_dataset(img,spec,0.5,BinaryDenoisingDataset)\n",
    "binary_test_dataset_50 = get_reduced_dataset(test_img,test_spec,0.5,BinaryDenoisingDataset)\n",
    "binary_dataloader_50 = DataLoader(binary_dataset_50, batch_size=32, shuffle=True)\n",
    "binary_dataloader_test_50 = DataLoader(binary_test_dataset_50, batch_size=32, shuffle=False)\n",
    "\n",
    "binary_dataset_25 = get_reduced_dataset(img,spec,0.25,BinaryDenoisingDataset)\n",
    "binary_test_dataset_25 = get_reduced_dataset(test_img,test_spec,0.25,BinaryDenoisingDataset)\n",
    "binary_dataloader_25 = DataLoader(binary_dataset_25, batch_size=32, shuffle=True)\n",
    "binary_dataloader_test_25 = DataLoader(binary_test_dataset_25, batch_size=32, shuffle=False)\n",
    "\n",
    "binary_dataset_10 = get_reduced_dataset(img,spec,0.1,BinaryDenoisingDataset)\n",
    "binary_test_dataset_10 = get_reduced_dataset(test_img,test_spec,0.1,BinaryDenoisingDataset)\n",
    "binary_dataloader_10 = DataLoader(binary_dataset_10, batch_size=32, shuffle=True)\n",
    "binary_dataloader_test_10 = DataLoader(binary_test_dataset_10, batch_size=32, shuffle=False)\n",
    "\n",
    "rici_dataset_75 = get_reduced_dataset(img,spec,0.75,RicianDenoisingDataset)\n",
    "rici_test_dataset_75 = get_reduced_dataset(test_img,test_spec,0.75,RicianDenoisingDataset)\n",
    "rici_dataloader_75 = DataLoader(rici_dataset_75, batch_size=32, shuffle=True)\n",
    "rici_dataloader_test_75 = DataLoader(rici_test_dataset_75, batch_size=32, shuffle=False)\n",
    "\n",
    "rici_dataset_50 = get_reduced_dataset(img,spec,0.5,RicianDenoisingDataset)\n",
    "rici_test_dataset_50 = get_reduced_dataset(test_img,test_spec,0.5,RicianDenoisingDataset)\n",
    "rici_dataloader_50 = DataLoader(rici_dataset_50, batch_size=32, shuffle=True)\n",
    "rici_dataloader_test_50 = DataLoader(rici_test_dataset_50, batch_size=32, shuffle=False)\n",
    "\n",
    "rici_dataset_25 = get_reduced_dataset(img,spec,0.25,RicianDenoisingDataset)\n",
    "rici_test_dataset_25 = get_reduced_dataset(test_img,test_spec,0.25,RicianDenoisingDataset)\n",
    "rici_dataloader_25 = DataLoader(rici_dataset_25, batch_size=32, shuffle=True)\n",
    "rici_dataloader_test_25 = DataLoader(rici_test_dataset_25, batch_size=32, shuffle=False)\n",
    "\n",
    "rici_dataset_10 = get_reduced_dataset(img,spec,0.1,RicianDenoisingDataset)\n",
    "rici_test_dataset_10 = get_reduced_dataset(test_img,test_spec,0.1,RicianDenoisingDataset)\n",
    "rici_dataloader_10 = DataLoader(rici_dataset_10, batch_size=32, shuffle=True)\n",
    "rici_dataloader_test_10 = DataLoader(rici_test_dataset_10, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e2af08",
   "metadata": {},
   "source": [
    "## Binary mask denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f9bb1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "binaryunet75 = Unet().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(binaryunet75.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "binary_unet75_train_loss,binary_unet75_test_loss = binary_train(binaryunet75, binary_dataloader_75, binary_dataloader_test_75, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_binary_unet_75.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(binary_unet75_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(binary_unet75_train_loss, label='train loss')\n",
    "plt.plot(binary_unet75_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84edce9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "binarycnndmri75 = CNNDMRI().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(binarycnndmri75.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "binary_cnndmri75_train_loss,binary_cnndmri75_test_loss = binary_train(binarycnndmri75, binary_dataloader_75, binary_dataloader_test_75, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_binary_cnndmri_75.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(binary_cnndmri75_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(binary_cnndmri75_train_loss, label='train loss')\n",
    "plt.plot(binary_cnndmri75_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90955edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "binarywsta75 = WSTAutoencoder().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(binarywsta75.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "binary_wsta75_train_loss,binary_wsta75_test_loss = binary_train(binarywsta75, binary_dataloader_75, binary_dataloader_test_75, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_binary_wsta_75.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(binary_wsta75_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(binary_wsta75_train_loss, label='train loss')\n",
    "plt.plot(binary_wsta75_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e8dad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(binary_wsta75_train_loss, label='WSTA architecture')\n",
    "plt.plot(binary_unet75_train_loss, label='UNet architecture')\n",
    "plt.plot(binary_cnndmri75_train_loss, label='CNNDMRI architecture')\n",
    "plt.title('Model comparison .75 dataset')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d83acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "binaryunet50 = Unet().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(binaryunet50.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "binary_unet50_train_loss,binary_unet50_test_loss = binary_train(binaryunet50, binary_dataloader_50, binary_dataloader_test_50, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_binary_unet_50.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(binary_unet50_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(binary_unet50_train_loss, label='train loss')\n",
    "plt.plot(binary_unet50_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7584dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "binarycnndmri50 = CNNDMRI().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(binarycnndmri50.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "binary_cnndmri50_train_loss,binary_cnndmri50_test_loss = binary_train(binarycnndmri50, binary_dataloader_50, binary_dataloader_test_50, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_binary_cnndmri_50.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(binary_cnndmri50_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(binary_cnndmri50_train_loss, label='train loss')\n",
    "plt.plot(binary_cnndmri50_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba3a785",
   "metadata": {},
   "outputs": [],
   "source": [
    "binarywsta50 = WSTAutoencoder().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(binarywsta50.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "binary_wsta50_train_loss,binary_wsta50_test_loss = binary_train(binarywsta50, binary_dataloader_50, binary_dataloader_test_50, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_binary_wsta_50.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(binary_wsta50_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(binary_wsta50_train_loss, label='train loss')\n",
    "plt.plot(binary_wsta50_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2673a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(binary_wsta50_train_loss, label='WSTA architecture')\n",
    "plt.plot(binary_unet50_train_loss, label='UNet architecture')\n",
    "plt.plot(binary_cnndmri50_train_loss, label='CNNDMRI architecture')\n",
    "plt.title('Model comparison .50 dataset')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d081c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "binaryunet25 = Unet().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(binaryunet25.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "binary_unet25_train_loss,binary_unet25_test_loss = binary_train(binaryunet25, binary_dataloader_25, binary_dataloader_test_25, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_binary_unet_25.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(binary_unet25_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(binary_unet25_train_loss, label='train loss')\n",
    "plt.plot(binary_unet25_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d735bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "binarycnndmri25 = CNNDMRI().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(binarycnndmri25.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "binary_cnndmri25_train_loss,binary_cnndmri25_test_loss = binary_train(binarycnndmri25, binary_dataloader_25, binary_dataloader_test_25, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_binary_cnndmri_25.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(binary_cnndmri25_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(binary_cnndmri25_train_loss, label='train loss')\n",
    "plt.plot(binary_cnndmri25_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90409f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "binarywsta25 = WSTAutoencoder().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(binarywsta25.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)    \n",
    "binary_wsta25_train_loss,binary_wsta25_test_loss = binary_train(binarywsta25, binary_dataloader_25, binary_dataloader_test_25, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_binary_wsta_25.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(binary_wsta25_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(binary_wsta25_train_loss, label='train loss')\n",
    "plt.plot(binary_wsta25_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a6e435",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(binary_wsta25_train_loss, label='WSTA architecture')\n",
    "plt.plot(binary_unet25_train_loss, label='UNet architecture')\n",
    "plt.plot(binary_cnndmri25_train_loss, label='CNNDMRI architecture')\n",
    "plt.title('Model comparison .25 dataset')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb5a72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "binaryunet10 = Unet().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(binaryunet10.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "binary_unet10_train_loss,binary_unet10_test_loss = binary_train(binaryunet10, binary_dataloader_10, binary_dataloader_test_10, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_binary_unet_10.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(binary_unet10_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(binary_unet10_train_loss, label='train loss')\n",
    "plt.plot(binary_unet10_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5d6755",
   "metadata": {},
   "outputs": [],
   "source": [
    "binarycnndmri10 = CNNDMRI().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(binarycnndmri10.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "binary_cnndmri10_train_loss,binary_cnndmri10_test_loss = binary_train(binarycnndmri10, binary_dataloader_10, binary_dataloader_test_10, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_binary_cnndmri_10.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(binary_cnndmri10_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(binary_cnndmri10_train_loss, label='train loss')\n",
    "plt.plot(binary_cnndmri10_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398e28d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "binarywsta10 = WSTAutoencoder().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(binarywsta10.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)    \n",
    "binary_wsta10_train_loss,binary_wsta10_test_loss = binary_train(binarywsta10, binary_dataloader_10, binary_dataloader_test_10, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_binary_wsta_10.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(binary_wsta10_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(binary_wsta10_train_loss, label='train loss')\n",
    "plt.plot(binary_wsta10_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772146a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(binary_wsta10_train_loss, label='WSTA architecture')\n",
    "plt.plot(binary_unet10_train_loss, label='UNet architecture')\n",
    "plt.plot(binary_cnndmri10_train_loss, label='CNNDMRI architecture')\n",
    "plt.title('Model comparison .10 dataset')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0641d72e",
   "metadata": {},
   "source": [
    "## Rician Noise Denoising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d40906",
   "metadata": {},
   "outputs": [],
   "source": [
    "riciunet75 = Unet().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(riciunet75.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "rici_unet75_train_loss,rici_unet75_test_loss = ricitrain(riciunet75, rici_dataloader_75, rici_dataloader_test_75, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_rici_unet_75.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(rici_unet75_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(rici_unet75_train_loss, label='train loss')\n",
    "plt.plot(rici_unet75_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cda277",
   "metadata": {},
   "outputs": [],
   "source": [
    "ricicnndmri75 = CNNDMRI().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(ricicnndmri75.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "rici_cnndmri75_train_loss,rici_cnndmri75_test_loss = ricitrain(ricicnndmri75, rici_dataloader_75, rici_dataloader_test_75, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_rici_cnndmri_75.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(rici_cnndmri75_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(rici_cnndmri75_train_loss, label='train loss')\n",
    "plt.plot(rici_cnndmri75_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9027f8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "riciwsta75 = WSTAutoencoder().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(riciwsta75.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "rici_wsta75_train_loss,rici_wsta75_test_loss = ricitrain(riciwsta75, rici_dataloader_75, rici_dataloader_test_75, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_rici_wsta_75.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(rici_wsta75_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(rici_wsta75_train_loss, label='train loss')\n",
    "plt.plot(rici_wsta75_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05cf091",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(rici_wsta75_train_loss, label='WSTA architecture')\n",
    "plt.plot(rici_unet75_train_loss, label='UNet architecture')\n",
    "plt.plot(rici_cnndmri75_train_loss, label='CNNDMRI architecture')\n",
    "plt.title('Model comparison .75 dataset')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd1e8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "riciunet50 = Unet().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(riciunet50.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "rici_unet50_train_loss,rici_unet50_test_loss = ricitrain(riciunet50, rici_dataloader_50, rici_dataloader_test_50, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_rici_unet_50.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(rici_unet50_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(rici_unet50_train_loss, label='train loss')\n",
    "plt.plot(rici_unet50_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6712cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ricicnndmri50 = CNNDMRI().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(ricicnndmri50.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "rici_cnndmri50_train_loss,rici_cnndmri50_test_loss = ricitrain(ricicnndmri50, rici_dataloader_50, rici_dataloader_test_50, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_rici_cnndmri_50.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(rici_cnndmri50_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(rici_cnndmri50_train_loss, label='train loss')\n",
    "plt.plot(rici_cnndmri50_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfd9ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "riciwsta50 = WSTAutoencoder().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(riciwsta50.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "rici_wsta50_train_loss,rici_wsta50_test_loss = ricitrain(riciwsta50, rici_dataloader_50, rici_dataloader_test_50, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_rici_wsta_50.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(rici_wsta50_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(rici_wsta50_train_loss, label='train loss')\n",
    "plt.plot(rici_wsta50_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6656e8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(rici_wsta50_train_loss, label='WSTA architecture')\n",
    "plt.plot(rici_unet50_train_loss, label='UNet architecture')\n",
    "plt.plot(rici_cnndmri50_train_loss, label='CNNDMRI architecture')\n",
    "plt.title('Model comparison .50 dataset')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d51946",
   "metadata": {},
   "outputs": [],
   "source": [
    "riciunet25 = Unet().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(riciunet25.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "rici_unet25_train_loss,rici_unet25_test_loss = ricitrain(riciunet25, rici_dataloader_25, rici_dataloader_test_25, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_rici_unet_25.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(rici_unet25_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(rici_unet25_train_loss, label='train loss')\n",
    "plt.plot(rici_unet25_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cfdb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "ricicnndmri25 = CNNDMRI().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(ricicnndmri25.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "rici_cnndmri25_train_loss,rici_cnndmri25_test_loss = ricitrain(ricicnndmri25, rici_dataloader_25, rici_dataloader_test_25, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_rici_cnndmri_25.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(rici_cnndmri25_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(rici_cnndmri25_train_loss, label='train loss')\n",
    "plt.plot(rici_cnndmri25_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4d8597",
   "metadata": {},
   "outputs": [],
   "source": [
    "riciwsta25 = WSTAutoencoder().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(riciwsta25.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "rici_wsta25_train_loss,rici_wsta25_test_loss = ricitrain(riciwsta25, rici_dataloader_25, rici_dataloader_test_25, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_rici_wsta_25.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(rici_wsta25_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(rici_wsta25_train_loss, label='train loss')\n",
    "plt.plot(rici_wsta25_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354f6fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(rici_wsta25_train_loss, label='WSTA architecture')\n",
    "plt.plot(rici_unet25_train_loss, label='UNet architecture')\n",
    "plt.plot(rici_cnndmri25_train_loss, label='CNNDMRI architecture')\n",
    "plt.title('Model comparison .25 dataset')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d738f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "riciunet10 = Unet().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(riciunet10.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "rici_unet10_train_loss,rici_unet10_test_loss = ricitrain(riciunet10, rici_dataloader_10, rici_dataloader_test_10, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_rici_unet_10.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(rici_unet10_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(rici_unet10_train_loss, label='train loss')\n",
    "plt.plot(rici_unet10_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174fee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "ricicnndmri10 = CNNDMRI().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(ricicnndmri10.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "rici_cnndmri10_train_loss,rici_cnndmri10_test_loss = ricitrain(ricicnndmri10, rici_dataloader_10, rici_dataloader_test_10, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_rici_cnndmri_10.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(rici_cnndmri10_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(rici_cnndmri10_train_loss, label='train loss')\n",
    "plt.plot(rici_cnndmri10_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f05207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "riciwsta10 = WSTAutoencoder().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(riciwsta10.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "rici_wsta10_train_loss,rici_wsta10_test_loss = ricitrain(riciwsta10, rici_dataloader_10, rici_dataloader_test_10, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_rici_wsta_10.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(rici_wsta10_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(rici_wsta10_train_loss, label='train loss')\n",
    "plt.plot(rici_wsta10_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001bc301",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(rici_wsta10_train_loss, label='WSTA architecture')\n",
    "plt.plot(rici_unet10_train_loss, label='UNet architecture')\n",
    "plt.plot(rici_cnndmri10_train_loss, label='CNNDMRI architecture')\n",
    "plt.title('Model comparison .10 dataset')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ed5b02",
   "metadata": {},
   "source": [
    "## Even less datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e749a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_dataset_05 = get_reduced_dataset(img,spec,0.05,BinaryDenoisingDataset)\n",
    "binary_test_dataset_05 = get_reduced_dataset(test_img,test_spec,0.05,BinaryDenoisingDataset)\n",
    "binary_dataloader_05 = DataLoader(binary_dataset_05, batch_size=32, shuffle=True)\n",
    "binary_dataloader_test_05 = DataLoader(binary_test_dataset_05, batch_size=32, shuffle=False)\n",
    "\n",
    "rici_dataset_05 = get_reduced_dataset(img,spec,0.05,RicianDenoisingDataset)\n",
    "rici_test_dataset_05 = get_reduced_dataset(test_img,test_spec,0.05,RicianDenoisingDataset)\n",
    "rici_dataloader_05 = DataLoader(rici_dataset_05, batch_size=32, shuffle=True)\n",
    "rici_dataloader_test_05 = DataLoader(rici_test_dataset_05, batch_size=32, shuffle=False)\n",
    "\n",
    "binary_dataset_025 = get_reduced_dataset(img,spec,0.025,BinaryDenoisingDataset)\n",
    "binary_test_dataset_025 = get_reduced_dataset(test_img,test_spec,0.025,BinaryDenoisingDataset)\n",
    "binary_dataloader_025 = DataLoader(binary_dataset_025, batch_size=32, shuffle=True)\n",
    "binary_dataloader_test_025 = DataLoader(binary_test_dataset_025, batch_size=32, shuffle=False)\n",
    "\n",
    "rici_dataset_025 = get_reduced_dataset(img,spec,0.025,RicianDenoisingDataset)\n",
    "rici_test_dataset_025 = get_reduced_dataset(test_img,test_spec,0.025,RicianDenoisingDataset)\n",
    "rici_dataloader_025 = DataLoader(rici_dataset_025, batch_size=32, shuffle=True)\n",
    "rici_dataloader_test_025 = DataLoader(rici_test_dataset_025, batch_size=32, shuffle=False)\n",
    "\n",
    "binary_dataset_0125 = get_reduced_dataset(img,spec,0.0125,BinaryDenoisingDataset)\n",
    "binary_test_dataset_0125 = get_reduced_dataset(test_img,test_spec,0.0125,BinaryDenoisingDataset)\n",
    "binary_dataloader_0125 = DataLoader(binary_dataset_0125, batch_size=32, shuffle=True)\n",
    "binary_dataloader_test_0125 = DataLoader(binary_test_dataset_0125, batch_size=32, shuffle=False)\n",
    "\n",
    "rici_dataset_0125 = get_reduced_dataset(img,spec,0.0125,RicianDenoisingDataset)\n",
    "rici_test_dataset_0125 = get_reduced_dataset(test_img,test_spec,0.0125,RicianDenoisingDataset)\n",
    "rici_dataloader_0125 = DataLoader(rici_dataset_0125, batch_size=32, shuffle=True)\n",
    "rici_dataloader_test_0125 = DataLoader(rici_test_dataset_0125, batch_size=32, shuffle=False)\n",
    "\n",
    "binary_dataset_005 = get_reduced_dataset(img,spec,0.005,BinaryDenoisingDataset)\n",
    "binary_test_dataset_005 = get_reduced_dataset(test_img,test_spec,0.005,BinaryDenoisingDataset)\n",
    "binary_dataloader_005 = DataLoader(binary_dataset_005, batch_size=32, shuffle=True)\n",
    "binary_dataloader_test_005 = DataLoader(binary_test_dataset_005, batch_size=32, shuffle=False)\n",
    "\n",
    "rici_dataset_005 = get_reduced_dataset(img,spec,0.005,RicianDenoisingDataset)\n",
    "rici_test_dataset_005 = get_reduced_dataset(test_img,test_spec,0.005,RicianDenoisingDataset)\n",
    "rici_dataloader_005 = DataLoader(rici_dataset_005, batch_size=32, shuffle=True)\n",
    "rici_dataloader_test_005 = DataLoader(rici_test_dataset_005, batch_size=32, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b97414",
   "metadata": {},
   "outputs": [],
   "source": [
    "binaryunet05 = Unet().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(binaryunet05.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "binaryunet05_train_loss,binaryunet05_test_loss = binary_train(binaryunet05, binary_dataloader_05, binary_dataloader_test_05, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_binary_unet_05.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(binaryunet05_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(binaryunet05_train_loss, label='train loss')\n",
    "plt.plot(binaryunet05_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d843006",
   "metadata": {},
   "outputs": [],
   "source": [
    "binarycnndmri05 = CNNDMRI().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(binarycnndmri05.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "binarycnndmri05_train_loss,binarycnndmri05_test_loss = binary_train(binarycnndmri05, binary_dataloader_05, binary_dataloader_test_05, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_binary_cnndmri_05.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(binarycnndmri05_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(binarycnndmri05_train_loss, label='train loss')\n",
    "plt.plot(binarycnndmri05_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ae0b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "binarywsta05 = WSTAutoencoder().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(binarywsta05.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "binarywsta05_train_loss,binarywsta05_test_loss = binary_train(binarywsta05, binary_dataloader_05, binary_dataloader_test_05, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_binary_wsta_05.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(binarywsta05_train_loss, start=1): \n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(binarywsta05_train_loss, label='train loss')\n",
    "plt.plot(binarywsta05_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3effc3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(binarywsta05_train_loss, label='WSTA architecture')\n",
    "plt.plot(binaryunet05_train_loss, label='UNet architecture')\n",
    "plt.plot(binarycnndmri05_train_loss, label='CNN-DMRI architecture')\n",
    "plt.title('Model comparison .05 dataset')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202d659f",
   "metadata": {},
   "outputs": [],
   "source": [
    "binaryunet025 = Unet().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(binaryunet025.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "binaryunet025_train_loss,binaryunet025_test_loss = binary_train(binaryunet025, binary_dataloader_025, binary_dataloader_test_025, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_binary_unet_025.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(binaryunet025_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(binaryunet025_train_loss, label='train loss')\n",
    "plt.plot(binaryunet025_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19b2aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "binarycnndmri025 = CNNDMRI().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(binarycnndmri025.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "binarycnndmri025_train_loss,binarycnndmri025_test_loss = binary_train(binarycnndmri025, binary_dataloader_025, binary_dataloader_test_025, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_binary_cnndmri_025.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(binarycnndmri025_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(binarycnndmri025_train_loss, label='train loss')\n",
    "plt.plot(binarycnndmri025_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3025fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "binarywsta025 = WSTAutoencoder().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(binarywsta025.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "binarywsta025_train_loss,binarywsta025_test_loss = binary_train(binarywsta025, binary_dataloader_025, binary_dataloader_test_025, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_binary_wsta_025.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(binarywsta025_train_loss, start=1): \n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(binarywsta025_train_loss, label='train loss')\n",
    "plt.plot(binarywsta025_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acc63b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(binarywsta025_train_loss, label='WSTA architecture')\n",
    "plt.plot(binaryunet025_train_loss, label='UNet architecture')\n",
    "plt.plot(binarycnndmri025_train_loss, label='CNN-DMRI architecture')\n",
    "plt.title('Model comparison .025 dataset')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350129d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "binaryunet0125 = Unet().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(binaryunet0125.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "binaryunet0125_train_loss,binaryunet0125_test_loss = binary_train(binaryunet0125, binary_dataloader_0125, binary_dataloader_test_0125, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_binary_unet_0125.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(binaryunet0125_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(binaryunet0125_train_loss, label='train loss')\n",
    "plt.plot(binaryunet0125_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aba9c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "binarycnndmri0125 = CNNDMRI().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(binarycnndmri0125.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "binarycnndmri0125_train_loss,binarycnndmri0125_test_loss = binary_train(binarycnndmri0125, binary_dataloader_0125, binary_dataloader_test_0125, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_binary_cnndmri_0125.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(binarycnndmri0125_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(binarycnndmri0125_train_loss, label='train loss')\n",
    "plt.plot(binarycnndmri0125_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d51e6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "binarywsta0125 = WSTAutoencoder().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(binarywsta0125.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "binarywsta0125_train_loss,binarywsta0125_test_loss = binary_train(binarywsta0125, binary_dataloader_0125, binary_dataloader_test_0125, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_binary_wsta_0125.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(binarywsta0125_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(binarywsta0125_train_loss, label='train loss')\n",
    "plt.plot(binarywsta0125_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a350680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(binarywsta0125_train_loss, label='WSTA architecture')\n",
    "plt.plot(binaryunet0125_train_loss, label='UNet architecture')\n",
    "plt.plot(binarycnndmri0125_train_loss, label='CNN-DMRI architecture')\n",
    "plt.title('Model comparison .0125 dataset')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bac2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "binaryunet005 = Unet().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(binaryunet005.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "binaryunet005_train_loss,binaryunet005_test_loss = binary_train(binaryunet005, binary_dataloader_005, binary_dataloader_test_005, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_binary_unet_005.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(binaryunet005_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(binaryunet005_train_loss, label='train loss')\n",
    "plt.plot(binaryunet005_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718d6933",
   "metadata": {},
   "outputs": [],
   "source": [
    "binarycnndmri005 = CNNDMRI().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(binarycnndmri005.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "binarycnndmri005_train_loss,binarycnndmri005_test_loss = binary_train(binarycnndmri005, binary_dataloader_005, binary_dataloader_test_005, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_binary_cnndmri_005.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(binarycnndmri005_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(binarycnndmri005_train_loss, label='train loss')\n",
    "plt.plot(binarycnndmri005_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d8c484",
   "metadata": {},
   "outputs": [],
   "source": [
    "binarywsta005 = WSTAutoencoder().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(binarywsta005.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "binarywsta005_train_loss,binarywsta005_test_loss = binary_train(binarywsta005, binary_dataloader_005, binary_dataloader_test_005, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_binary_wsta_005.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(binarywsta005_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(binarywsta005_train_loss, label='train loss')\n",
    "plt.plot(binarywsta005_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d16bfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(binarywsta005_train_loss, label='WSTA architecture')\n",
    "plt.plot(binaryunet005_train_loss, label='UNet architecture')\n",
    "plt.plot(binarycnndmri005_train_loss, label='CNN-DMRI architecture')\n",
    "plt.title('Model comparison .005 dataset')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df5e954",
   "metadata": {},
   "outputs": [],
   "source": [
    "riciunet05 = Unet().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(riciunet05.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "riciunet05_train_loss,riciunet05_test_loss = ricitrain(riciunet05, rici_dataloader_05, rici_dataloader_test_05, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_rician_unet_05.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(riciunet05_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(riciunet05_train_loss, label='train loss')\n",
    "plt.plot(riciunet05_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b6129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ricicnndmri05 = CNNDMRI().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(ricicnndmri05.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "ricicnndmri05_train_loss,ricicnndmri05_test_loss = ricitrain(ricicnndmri05, rici_dataloader_05, rici_dataloader_test_05, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_rician_cnndmri_05.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(ricicnndmri05_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(ricicnndmri05_train_loss, label='train loss')\n",
    "plt.plot(ricicnndmri05_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8e2160",
   "metadata": {},
   "outputs": [],
   "source": [
    "riciwsta05 = WSTAutoencoder().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(riciwsta05.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "riciwsta05_train_loss,riciwsta05_test_loss = ricitrain(riciwsta05, rici_dataloader_05, rici_dataloader_test_05, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_rician_wsta_05.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(riciwsta05_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(riciwsta05_train_loss, label='train loss')\n",
    "plt.plot(riciwsta05_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c09e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(riciwsta05_train_loss, label='WSTA architecture')\n",
    "plt.plot(riciunet05_train_loss, label='UNet architecture')\n",
    "plt.plot(ricicnndmri05_train_loss, label='CNN-DMRI architecture')\n",
    "plt.title('Model comparison .05 dataset')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26219875",
   "metadata": {},
   "outputs": [],
   "source": [
    "riciunet025 = Unet().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(riciunet025.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "riciunet025_train_loss,riciunet025_test_loss = ricitrain(riciunet025, rici_dataloader_025, rici_dataloader_test_025, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_rician_unet_025.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(riciunet025_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(riciunet025_train_loss, label='train loss')\n",
    "plt.plot(riciunet025_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dfcfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ricicnndmri025 = CNNDMRI().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(ricicnndmri025.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "ricicnndmri025_train_loss,ricicnndmri025_test_loss = ricitrain(ricicnndmri025, rici_dataloader_025, rici_dataloader_test_025, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_rician_cnndmri_025.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(ricicnndmri025_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(ricicnndmri025_train_loss, label='train loss')\n",
    "plt.plot(ricicnndmri025_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771439dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "riciwsta025 = WSTAutoencoder().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(riciwsta025.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "riciwsta025_train_loss,riciwsta025_test_loss = ricitrain(riciwsta025, rici_dataloader_025, rici_dataloader_test_025, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_rician_wsta_025.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(riciwsta025_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(riciwsta025_train_loss, label='train loss')\n",
    "plt.plot(riciwsta025_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36329b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(riciwsta025_train_loss, label='WSTA architecture')\n",
    "plt.plot(riciunet025_train_loss, label='UNet architecture')\n",
    "plt.plot(ricicnndmri025_train_loss, label='CNN-DMRI architecture')\n",
    "plt.title('Model comparison .025 dataset')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fe9a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "riciunet0125 = Unet().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(riciunet0125.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "riciunet0125_train_loss,riciunet0125_test_loss = ricitrain(riciunet0125, rici_dataloader_0125, rici_dataloader_test_0125, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_rician_unet_0125.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(riciunet0125_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(riciunet0125_train_loss, label='train loss')\n",
    "plt.plot(riciunet0125_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f299b863",
   "metadata": {},
   "outputs": [],
   "source": [
    "ricicnndmri0125 = CNNDMRI().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(ricicnndmri0125.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "ricicnndmri0125_train_loss,ricicnndmri0125_test_loss = ricitrain(ricicnndmri0125, rici_dataloader_0125, rici_dataloader_test_0125, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_rician_cnndmri_0125.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(ricicnndmri0125_train_loss, start=1):    \n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(ricicnndmri0125_train_loss, label='train loss')\n",
    "plt.plot(ricicnndmri0125_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de859766",
   "metadata": {},
   "outputs": [],
   "source": [
    "riciwsta0125 = WSTAutoencoder().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(riciwsta0125.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "riciwsta0125_train_loss,riciwsta0125_test_loss = ricitrain(riciwsta0125, rici_dataloader_0125, rici_dataloader_test_0125, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_rician_wsta_0125.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(riciwsta0125_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(riciwsta0125_train_loss, label='train loss')\n",
    "plt.plot(riciwsta0125_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df0eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(riciwsta0125_train_loss, label='WSTA architecture')\n",
    "plt.plot(riciunet0125_train_loss, label='UNet architecture')\n",
    "plt.plot(ricicnndmri0125_train_loss, label='CNN-DMRI architecture')\n",
    "plt.title('Model comparison .0125 dataset')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b275fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "riciunet005 = Unet().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(riciunet005.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "riciunet005_train_loss,riciunet005_test_loss = ricitrain(riciunet005, rici_dataloader_005, rici_dataloader_test_005, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_rician_unet_005.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(riciunet005_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(riciunet005_train_loss, label='train loss')\n",
    "plt.plot(riciunet005_test_loss, label='test loss')    \n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5a6cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ricicnndmri005 = CNNDMRI().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(ricicnndmri005.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "ricicnndmri005_train_loss,ricicnndmri005_test_loss = ricitrain(ricicnndmri005, rici_dataloader_005, rici_dataloader_test_005, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_rician_cnndmri_005.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(ricicnndmri005_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(ricicnndmri005_train_loss, label='train loss')\n",
    "plt.plot(ricicnndmri005_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5269e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "riciwsta005 = WSTAutoencoder().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(riciwsta005.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "riciwsta005_train_loss,riciwsta005_test_loss = ricitrain(riciwsta005, rici_dataloader_005, rici_dataloader_test_005, loss_fn, optimizer, scheduler, 25)\n",
    "# with open('./Results/train_losses_rician_wsta_005.csv', mode='w', newline='') as file:\n",
    "#     writer = csv.writer(file)\n",
    "#     writer.writerow(['Epoch', 'Train Loss'])\n",
    "#     for i, loss in enumerate(riciwsta005_train_loss, start=1):\n",
    "#         writer.writerow([i, loss])\n",
    "plt.figure()\n",
    "plt.plot(riciwsta005_train_loss, label='train loss')\n",
    "plt.plot(riciwsta005_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503cfe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(riciwsta005_train_loss, label='WSTA architecture')\n",
    "plt.plot(riciunet005_train_loss, label='UNet architecture')\n",
    "plt.plot(ricicnndmri005_train_loss, label='CNN-DMRI architecture')\n",
    "plt.title('Model comparison .005 dataset')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
