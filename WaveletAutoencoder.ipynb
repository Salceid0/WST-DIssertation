{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dd3aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from kymatio.torch import Scattering2D\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "import nibabel as nib\n",
    "from scipy.fftpack import fft, ifft, fft2, ifft2, fftshift, ifftshift\n",
    "import PIL.Image\n",
    "import pickle\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bc3e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pkl(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "def fftshift2d(x, ifft=False):\n",
    "    assert (len(x.shape) == 2) and all([(s % 2 == 1) for s in x.shape])\n",
    "    s0 = (x.shape[0] // 2) + (0 if ifft else 1)\n",
    "    s1 = (x.shape[1] // 2) + (0 if ifft else 1)\n",
    "    x = np.concatenate([x[s0:, :], x[:s0, :]], axis=0)\n",
    "    x = np.concatenate([x[:, s1:], x[:, :s1]], axis=1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b83611",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruta = \"C:/Users/javit/Desktop/MRI datasets/datasets/ixi_train-001.pkl\"\n",
    "# ruta_test = \"C:/Users/javit/Desktop/MRI datasets/datasets/ixi_valid.pkl\"\n",
    "ruta = \"C:/Users/javit/Desktop/N2N/datasets/ixi_train.pkl\"\n",
    "ruta_test = \"C:/Users/javit/Desktop/N2N/datasets/ixi_valid.pkl\"\n",
    "img, spec = load_pkl(ruta)\n",
    "img=img[:,:-1,:-1] #images are now 255,255\n",
    "img = img.astype(np.float32) / 255.0 - 0.5 # normalize and make sure they are in range [-.5,.5]\n",
    "test_img, test_spec = load_pkl(ruta_test)\n",
    "test_img=test_img[:,:-1,:-1]\n",
    "test_img=test_img.astype(np.float32) / 255.0 - 0.5\n",
    "\n",
    "\n",
    "p_at_edge=0.025\n",
    "h = [s // 2 for s in (255,255)] #255\n",
    "r = [np.arange(s, dtype=np.float32) - h for s, h in zip((255,255), h)]\n",
    "r = [x ** 2 for x in r]\n",
    "r = (r[0][:, np.newaxis] + r[1][np.newaxis, :]) ** .5\n",
    "m = (p_at_edge ** (1./h[1])) ** r\n",
    "bern_mask = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b967bb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt_data(img, spec):\n",
    "    global bern_mask\n",
    "    mask = bern_mask\n",
    "    # print('Bernoulli probability at edge = %.5f' % mask[h[0], 0])\n",
    "    # print('Average Bernoulli probability = %.5f' % np.mean(mask))\n",
    "    keep = (np.random.uniform(0.0, 1.0, size=spec.shape)**2 < mask)\n",
    "    keep = keep & keep[::-1, ::-1]\n",
    "    sval = spec * keep\n",
    "    smsk = keep.astype(np.float32)\n",
    "    spec = fftshift2d(sval / (mask + ~keep), ifft=True) # Add 1.0 to not-kept values to prevent div-by-zero.\n",
    "    img = np.real(np.fft.ifft2(spec)).astype(np.float32)\n",
    "    return img, sval, smsk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d80181",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIDenoisingDataset(Dataset):\n",
    "    def __init__(self,clean_images,clean_specs,t=64,corrupt_fn=corrupt_data,augment_fn=None):\n",
    "        super(MRIDenoisingDataset, self).__init__()\n",
    "        self.clean_images = clean_images\n",
    "        self.clean_specs = clean_specs\n",
    "        self.t = t\n",
    "        self.corrupt_fn = corrupt_fn\n",
    "        self.augment_fn = augment_fn\n",
    "    def __len__(self):\n",
    "        return len(self.clean_images)\n",
    "    def __getitem__(self, idx):\n",
    "        img_clean= self.clean_images[idx]\n",
    "        spec_clean = self.clean_specs[idx]\n",
    "        # Data augmentation\n",
    "        if self.augment_fn:\n",
    "            img_clean,spec_clean = self.augment_fn(img_clean,spec_clean,t=self.t)        \n",
    "        # Corrupt data\n",
    "        cimg, cspec, cmask = self.corrupt_fn(img_clean,spec_clean)\n",
    "        img_noisy = torch.tensor(cimg,dtype=torch.float32)\n",
    "        spec_noisy = torch.tensor(cspec,dtype=torch.complex64)\n",
    "        mask = torch.tensor(cmask,dtype=torch.float32)\n",
    "        img_clean = torch.tensor(img_clean,dtype=torch.float32)\n",
    "        spec_clean = torch.tensor(spec_clean,dtype=torch.complex64)\n",
    "        return img_clean.unsqueeze(0), spec_clean.unsqueeze(0), img_noisy.unsqueeze(0), spec_noisy.unsqueeze(0), mask.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b81be17",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= MRIDenoisingDataset(img,spec)\n",
    "test_dataset = MRIDenoisingDataset(test_img,test_spec)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1712e26a",
   "metadata": {},
   "source": [
    "# Wavelet Scattering Transform autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e378544f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WSTAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WSTAutoencoder, self).__init__()\n",
    "        self.scattering2d = Scattering2D(J=2, L=8, shape=(256,256)) # [81,64,64]\n",
    "\n",
    "        #Decoder\n",
    "        self.conv0 = nn.Conv2d(81,64,3,stride=1,padding=1)\n",
    "        self.bn0 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.res1conv1 = nn.Conv2d(64,64,3,stride=1,padding=1)\n",
    "        self.res1bn1 = nn.BatchNorm2d(64)\n",
    "        self.res1conv2 = nn.Conv2d(64,64,3,stride=1,padding=1)\n",
    "        self.res1bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.res2conv1 = nn.Conv2d(64,64,3,stride=1,padding=1)\n",
    "        self.res2bn1 = nn.BatchNorm2d(64)\n",
    "        self.res2conv2 = nn.Conv2d(64,64,3,stride=1,padding=1)\n",
    "        self.res2bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.upsample1 = nn.Upsample(scale_factor=2) #[64,128,128]\n",
    "        self.conv1 = nn.Conv2d(64,32,3,stride=1,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.res3conv1 = nn.Conv2d(32,32,3,stride=1,padding=1)\n",
    "        self.res3bn1 = nn.BatchNorm2d(32)\n",
    "        self.res3conv2 = nn.Conv2d(32,32,3,stride=1,padding=1)\n",
    "        self.res3bn2 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.upsample2 = nn.Upsample(scale_factor=2) #[32,256,256]\n",
    "        self.conv2 = nn.Conv2d(33,16,3,stride=1,padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "\n",
    "        self.res4conv1 = nn.Conv2d(16,16,3,stride=1,padding=1)\n",
    "        self.res4bn1 = nn.BatchNorm2d(16)\n",
    "        self.res4conv2 = nn.Conv2d(16,16,3,stride=1,padding=1)\n",
    "        self.res4bn2 = nn.BatchNorm2d(16)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(16,9,3,stride=1,padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(9)\n",
    "\n",
    "        self.res5conv1 = nn.Conv2d(9,9,3,stride=1,padding=1)\n",
    "        self.res5bn1 = nn.BatchNorm2d(9)\n",
    "        self.res5conv2 = nn.Conv2d(9,9,3,stride=1,padding=1)\n",
    "        self.res5bn2 = nn.BatchNorm2d(9)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(9,1,3,stride=1,padding=1)\n",
    "        # self.bn4 = nn.BatchNorm2d(1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        original_in = F.pad(x, (0,1,0,1), mode='constant', value=-0.5)\n",
    "        x = self.scattering2d(original_in).squeeze(1)\n",
    "        \n",
    "        x = self.conv0(x)\n",
    "        x = F.leaky_relu(self.bn0(x))\n",
    "\n",
    "        resblock1_input =x\n",
    "        x = self.res1conv1(x)\n",
    "        x = F.leaky_relu(self.res1bn1(x))\n",
    "\n",
    "        x = self.res1conv2(x)\n",
    "        x = F.leaky_relu(self.res1bn2(x))\n",
    "\n",
    "        x = x + resblock1_input\n",
    "        resblock2_input = x\n",
    "        x = self.res2conv1(x)\n",
    "\n",
    "        x = self.res2conv2(x)\n",
    "        x = F.leaky_relu(self.res2bn2(x))\n",
    "\n",
    "        x = x + resblock2_input\n",
    "        x = self.upsample1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = F.leaky_relu(self.bn1(x))\n",
    "\n",
    "        resblock3_input = x\n",
    "        x = self.res3conv1(x)\n",
    "        x = F.leaky_relu(self.res3bn1(x))\n",
    "\n",
    "        x = self.res3conv2(x)\n",
    "        x = F.leaky_relu(self.res3bn2(x))\n",
    "        x = x + resblock3_input\n",
    "\n",
    "        x = self.upsample2(x)\n",
    "        x = torch.cat((x, original_in), dim=1)\n",
    "        x = self.conv2(x)\n",
    "        x = F.leaky_relu(self.bn2(x))\n",
    "\n",
    "        resblock4_input = x\n",
    "        x = self.res4conv1(x)\n",
    "        x = F.leaky_relu(self.res4bn1(x))\n",
    "        x = self.res4conv2(x)\n",
    "        x = F.leaky_relu(self.res4bn2(x))\n",
    "        x = x + resblock4_input\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = F.leaky_relu(self.bn3(x))\n",
    "\n",
    "        resblock5_input = x\n",
    "        x = self.res5conv1(x)\n",
    "        x = F.leaky_relu(self.res5bn1(x))\n",
    "        x = self.res5conv2(x)\n",
    "        x = F.leaky_relu(self.res5bn2(x))\n",
    "        x = x + resblock5_input\n",
    "        x = self.conv4(x)\n",
    "        # x = F.sigmoid(x)-0.5\n",
    "        return x[:,:,:-1,:-1]\n",
    "model= WSTAutoencoder().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ca0f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, (1, 255, 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0b4f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()\n",
    "# the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "def train(net, trainLoader,testLoader, loss_fn, optimizer, scheduler, NUM_EPOCHS):\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        net.train()\n",
    "        running_loss = 0.0\n",
    "        with tqdm(trainLoader, unit=\"batch\") as tepoch:\n",
    "            for data in tepoch:\n",
    "                tepoch.set_description(f\"Epoch {epoch+1}\")\n",
    "                img_clean,spec_clean, img_noisy, spec_noisy, mask = data\n",
    "                img_noisy = img_noisy.to(device)\n",
    "                img_clean = img_clean.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(img_noisy)\n",
    "                loss = loss_fn(outputs, img_clean)\n",
    "                # backpropagation\n",
    "                loss.backward()\n",
    "                # update the parameters\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                tepoch.set_postfix(loss=loss)    \n",
    "            \n",
    "            loss = running_loss / len(trainLoader)\n",
    "            train_loss.append(loss)\n",
    "        scheduler.step()\n",
    "        net.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            with tqdm(testLoader, unit=\"batch\") as tepoch:\n",
    "                for data in tepoch:\n",
    "                    img_clean,spec_clean, img_noisy, spec_noisy, mask = data\n",
    "                    img_noisy = img_noisy.to(device)\n",
    "                    img_clean = img_clean.to(device)\n",
    "                    outputs = net(img_noisy)\n",
    "                    outputs = torch.clamp(outputs, -.5, .5)\n",
    "                    loss = loss_fn(outputs, img_clean)\n",
    "                    val_loss += loss.item()\n",
    "                    tepoch.set_postfix(loss=loss)    \n",
    "                \n",
    "                loss = val_loss / len(testLoader)\n",
    "                test_loss.append(loss)\n",
    "        \n",
    "    \n",
    "    return train_loss,test_loss         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f76a091",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_wsta_train_loss,binary_wsta_test_loss = train(model, dataloader, dataloader_test, loss_fn, optimizer, scheduler, 25)\n",
    "plt.figure()\n",
    "plt.plot(binary_wsta_train_loss, label='train loss')\n",
    "plt.plot(binary_wsta_test_loss, label='test loss')\n",
    "plt.legend()\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "with open('./Results/train_losses_binary_wsta_with_eval.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Epoch', 'Train Loss'])  # encabezado opcional\n",
    "    for i, loss in enumerate(binary_wsta_train_loss, start=1):\n",
    "        writer.writerow([i, loss])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
