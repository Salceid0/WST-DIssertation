{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78efba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm\n",
    "from kymatio.torch import Scattering2D\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "\n",
    "import pickle\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c28708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pkl(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "def fftshift2d(x, ifft=False):\n",
    "    assert (len(x.shape) == 2) and all([(s % 2 == 1) for s in x.shape])\n",
    "    s0 = (x.shape[0] // 2) + (0 if ifft else 1)\n",
    "    s1 = (x.shape[1] // 2) + (0 if ifft else 1)\n",
    "    x = np.concatenate([x[s0:, :], x[:s0, :]], axis=0)\n",
    "    x = np.concatenate([x[:, s1:], x[:, :s1]], axis=1)\n",
    "    return x\n",
    "def fftshift3d(x, ifft):\n",
    "    assert len(x.shape) == 4\n",
    "    s0 = (x.shape[2] // 2) + (0 if ifft else 1)\n",
    "    s1 = (x.shape[3] // 2) + (0 if ifft else 1)\n",
    "    x = torch.cat([x[:,:, s0:, :], x[:,:, :s0, :]], dim=2)\n",
    "    x = torch.cat([x[:,:, :, s1:], x[:,:, :, :s1]], dim=3)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc21ffe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruta = \"C:/Users/javit/Desktop/MRI datasets/datasets/ixi_train-001.pkl\"\n",
    "# ruta_test = \"C:/Users/javit/Desktop/MRI datasets/datasets/ixi_valid.pkl\"\n",
    "ruta = \"C:/Users/javit/Desktop/N2N/datasets/ixi_train.pkl\"\n",
    "ruta_test = \"C:/Users/javit/Desktop/N2N/datasets/ixi_valid.pkl\"\n",
    "img, spec = load_pkl(ruta)\n",
    "img=img[:,:-1,:-1] #images are now 255,255\n",
    "img = img.astype(np.float32) / 255.0 - 0.5 # normalize and make sure they are in range [-.5,.5]\n",
    "test_img, test_spec = load_pkl(ruta_test)\n",
    "test_img=test_img[:,:-1,:-1]\n",
    "test_img=test_img.astype(np.float32) / 255.0 - 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323252aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_at_edge=0.025\n",
    "h = [s // 2 for s in (255,255)] #255\n",
    "r = [np.arange(s, dtype=np.float32) - h for s, h in zip((255,255), h)]\n",
    "r = [x ** 2 for x in r]\n",
    "r = (r[0][:, np.newaxis] + r[1][np.newaxis, :]) ** .5\n",
    "m = (p_at_edge ** (1./h[1])) ** r\n",
    "bern_mask = m\n",
    "\n",
    "def corrupt_data_binary(img, spec):\n",
    "    global bern_mask\n",
    "    mask = bern_mask\n",
    "    # print('Bernoulli probability at edge = %.5f' % mask[h[0], 0])\n",
    "    # print('Average Bernoulli probability = %.5f' % np.mean(mask))\n",
    "    keep = (np.random.uniform(0.0, 1.0, size=spec.shape)**2 < mask)\n",
    "    keep = keep & keep[::-1, ::-1]\n",
    "    sval = spec * keep\n",
    "    smsk = keep.astype(np.float32)\n",
    "    spec = fftshift2d(sval / (mask + ~keep), ifft=True) # Add 1.0 to not-kept values to prevent div-by-zero.\n",
    "    img = np.real(np.fft.ifft2(spec)).astype(np.float32)\n",
    "    return img, sval, smsk\n",
    "\n",
    "class BinaryDenoisingDataset(Dataset):\n",
    "    def __init__(self,clean_images,clean_specs,corrupt_fn=corrupt_data_binary):\n",
    "        super(BinaryDenoisingDataset, self).__init__()\n",
    "        self.clean_images = clean_images\n",
    "        self.clean_specs = clean_specs\n",
    "        self.corrupt_fn = corrupt_fn\n",
    "    def __len__(self):\n",
    "        return len(self.clean_images)\n",
    "    def __getitem__(self, idx):\n",
    "        img_clean= self.clean_images[idx]\n",
    "        spec_clean = self.clean_specs[idx]\n",
    "        # Corrupt data\n",
    "        cimg, cspec, cmask = self.corrupt_fn(img_clean,spec_clean)\n",
    "        img_noisy = torch.tensor(cimg,dtype=torch.float32)\n",
    "        spec_noisy = torch.tensor(cspec,dtype=torch.complex64)\n",
    "        mask = torch.tensor(cmask,dtype=torch.float32)\n",
    "        img_clean = torch.tensor(img_clean,dtype=torch.float32)\n",
    "        spec_clean = torch.tensor(spec_clean,dtype=torch.complex64)\n",
    "        return img_clean.unsqueeze(0), spec_clean.unsqueeze(0), img_noisy.unsqueeze(0), spec_noisy.unsqueeze(0), mask.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bf41a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt_data_rician(img,noise_percent):\n",
    "    sigma =(noise_percent/100)*img.max().item()\n",
    "    noise1 = np.random.normal(0,sigma,img.shape)\n",
    "    noise2 = np.random.normal(0,sigma,img.shape)\n",
    "    noisy_img = np.sqrt((img+noise1)**2+noise2**2)\n",
    "    return noisy_img\n",
    "class RicianDenoisingDataset(Dataset):\n",
    "    def __init__(self,clean_images,t=64,corrupt_fn=corrupt_data_rician,augment_fn=None):\n",
    "        super(RicianDenoisingDataset, self).__init__()\n",
    "        self.clean_images = clean_images\n",
    "        self.t = t\n",
    "        self.corrupt_fn = corrupt_fn\n",
    "        self.augment_fn = augment_fn\n",
    "    def __len__(self):\n",
    "        return len(self.clean_images)\n",
    "    def __getitem__(self, idx):\n",
    "        img_clean= self.clean_images[idx]+0.5 #now img in[0,1] range\n",
    "        # Data augmentation\n",
    "        if self.augment_fn:\n",
    "            img_clean,spec_clean = self.augment_fn(img_clean,spec_clean,t=self.t)        \n",
    "        # Corrupt data\n",
    "        cimg = self.corrupt_fn(img_clean,11)\n",
    "        img_noisy = torch.tensor(cimg,dtype=torch.float32).clamp(0,1)\n",
    "        img_clean = torch.tensor(img_clean,dtype=torch.float32).clamp(0,1)\n",
    "        return img_clean.unsqueeze(0)-0.5, img_noisy.unsqueeze(0)-0.5 #Again in [-.5,.5] range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b40a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34be7f3",
   "metadata": {},
   "source": [
    "# Unet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2393021e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Unet, self).__init__()\n",
    "\n",
    "        #Encoder\n",
    "        self.conv0 = nn.Conv2d(1, 48, 3, stride=1, padding=1)\n",
    "        self.conv1 = nn.Conv2d(48, 48, 3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(48, 48, 3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(48, 48, 3, stride=1, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(48, 48, 3, stride=1, padding=1)\n",
    "        self.pool4 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv5 = nn.Conv2d(48, 48, 3, stride=1, padding=1)\n",
    "        self.pool5 = nn.MaxPool2d(2, 2)\n",
    "\n",
    "        self.conv6 = nn.Conv2d(48, 48, 3, stride=1, padding=1)\n",
    "\n",
    "        #Decoder\n",
    "        self.upsample5 = nn.Upsample(scale_factor=2)\n",
    "        self.deconv5a = nn.Conv2d(96, 96, 3, stride=1, padding=1)\n",
    "        self.deconv5b = nn.Conv2d(96, 96, 3, stride=1, padding=1)\n",
    "\n",
    "        self.upsample4 = nn.Upsample(scale_factor=2)\n",
    "        self.deconv4a = nn.Conv2d(144, 96, 3, stride=1, padding=1)\n",
    "        self.deconv4b = nn.Conv2d(96, 96, 3, stride=1, padding=1)\n",
    "\n",
    "        self.upsample3 = nn.Upsample(scale_factor=2)\n",
    "        self.deconv3a = nn.Conv2d(144, 96, 3, stride=1, padding=1)\n",
    "        self.deconv3b = nn.Conv2d(96, 96, 3, stride=1, padding=1)\n",
    "\n",
    "        self.upsample2 = nn.Upsample(scale_factor=2)\n",
    "        self.deconv2a = nn.Conv2d(144, 96, 3, stride=1, padding=1)\n",
    "        self.deconv2b = nn.Conv2d(96, 96, 3, stride=1, padding=1)\n",
    "\n",
    "        self.upsample1 = nn.Upsample(scale_factor=2)\n",
    "        self.deconv1a = nn.Conv2d(97, 64, 3, stride=1, padding=1)\n",
    "        self.deconv1b = nn.Conv2d(64, 32, 3, stride=1, padding=1)\n",
    "        self.deconv1c = nn.Conv2d(32, 1, 3, stride=1, padding=1)\n",
    "\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        original_in = F.pad(x, (0,1,0,1), mode='constant', value=-0.5)\n",
    "        x = F.leaky_relu(self.conv0(original_in))\n",
    "        x = F.leaky_relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        pool1 = x\n",
    "        x = F.leaky_relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        pool2 = x\n",
    "        x = F.leaky_relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "        pool3 = x\n",
    "        x = F.leaky_relu(self.conv4(x))\n",
    "        x = self.pool4(x)\n",
    "        pool4 = x\n",
    "        x = F.leaky_relu(self.conv5(x))\n",
    "        x = self.pool5(x)\n",
    "        x = F.leaky_relu(self.conv6(x))\n",
    "        x = self.upsample5(x)\n",
    "        x = torch.cat((x, pool4), 1)\n",
    "        x = F.leaky_relu(self.deconv5a(x))\n",
    "        x = F.leaky_relu(self.deconv5b(x))\n",
    "        x = self.upsample4(x)\n",
    "        x = torch.cat((x, pool3), 1)\n",
    "        x = F.leaky_relu(self.deconv4a(x))\n",
    "        x = F.leaky_relu(self.deconv4b(x))\n",
    "        x = self.upsample3(x)\n",
    "        x = torch.cat((x, pool2), 1)\n",
    "        x = F.leaky_relu(self.deconv3a(x))\n",
    "        x = F.leaky_relu(self.deconv3b(x))\n",
    "        x = self.upsample2(x)\n",
    "        x = torch.cat((x, pool1), 1)\n",
    "        x = F.leaky_relu(self.deconv2a(x))\n",
    "        x = F.leaky_relu(self.deconv2b(x))\n",
    "        x = self.upsample1(x)\n",
    "        x = torch.cat((x, original_in), 1)\n",
    "        x = F.leaky_relu(self.deconv1a(x))\n",
    "        x = F.leaky_relu(self.deconv1b(x))\n",
    "        x = self.deconv1c(x)\n",
    "        return x[:,:,:-1,:-1]\n",
    "    \n",
    "\n",
    "class CNNDMRI(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNDMRI, self).__init__()\n",
    "\n",
    "        #Initial convolutions\n",
    "        self.conv1 = nn.Conv2d(1,64,kernel_size=3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(64,64,kernel_size=3,padding=1)\n",
    "\n",
    "        # Encoder layers\n",
    "        self.enc1 = nn.Conv2d(64, 128, kernel_size=3, padding=1, stride=2)\n",
    "        self.enc2 = nn.Conv2d(128, 128, kernel_size=3, padding=1, stride=2)\n",
    "\n",
    "        #Residual blocks\n",
    "        self.res1conv1 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.res1conv2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.res2conv1 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.res2conv2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.res3conv1 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.res3conv2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "        self.res4conv1 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn7 = nn.BatchNorm2d(128)\n",
    "        self.res4conv2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn8 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # Decoder layers\n",
    "        self.dec1 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2,padding=1,output_padding=1)\n",
    "        self.dec2 = nn.ConvTranspose2d(64, 64, kernel_size=3, stride=2,padding=1)\n",
    "\n",
    "        #Final convolution\n",
    "        self.out = nn.Conv2d(64, 1, kernel_size=3, padding=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        original_noisy = x\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        #Encoder\n",
    "        x = F.relu(self.enc1(x))\n",
    "        x = F.relu(self.enc2(x))\n",
    "        #Residual blocks\n",
    "        res1 = x\n",
    "        x = self.res1conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.res1conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x += res1\n",
    "\n",
    "        res2 = x\n",
    "        x = self.res2conv1(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.res2conv2(x)\n",
    "        x = self.bn4(x)\n",
    "        x += res2\n",
    "\n",
    "        res3 = x\n",
    "        x = self.res3conv1(x)\n",
    "        x = F.relu(self.bn5(x))\n",
    "        x = self.res3conv2(x)\n",
    "        x = self.bn6(x)\n",
    "        x += res3\n",
    "\n",
    "        res4 = x\n",
    "        x = self.res4conv1(x)\n",
    "        x = F.relu(self.bn7(x))\n",
    "        x = self.res4conv2(x)\n",
    "        x = self.bn8(x)\n",
    "        x += res4\n",
    "        # Decoder\n",
    "        x = F.relu(self.dec1(x))\n",
    "        x = F.relu(self.dec2(x))\n",
    "        #Final convolution\n",
    "        x = self.out(x)\n",
    "        x += original_noisy\n",
    "        return x\n",
    "    \n",
    "class WSTAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WSTAutoencoder, self).__init__()\n",
    "        self.scattering2d = Scattering2D(J=2, L=8, shape=(256,256)) # [81,64,64]\n",
    "\n",
    "        #Decoder\n",
    "        self.conv0 = nn.Conv2d(81,64,3,stride=1,padding=1)\n",
    "        self.bn0 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.res1conv1 = nn.Conv2d(64,64,3,stride=1,padding=1)\n",
    "        self.res1bn1 = nn.BatchNorm2d(64)\n",
    "        self.res1conv2 = nn.Conv2d(64,64,3,stride=1,padding=1)\n",
    "        self.res1bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.res2conv1 = nn.Conv2d(64,64,3,stride=1,padding=1)\n",
    "        self.res2bn1 = nn.BatchNorm2d(64)\n",
    "        self.res2conv2 = nn.Conv2d(64,64,3,stride=1,padding=1)\n",
    "        self.res2bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.upsample1 = nn.Upsample(scale_factor=2) #[64,128,128]\n",
    "        self.conv1 = nn.Conv2d(64,32,3,stride=1,padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.res3conv1 = nn.Conv2d(32,32,3,stride=1,padding=1)\n",
    "        self.res3bn1 = nn.BatchNorm2d(32)\n",
    "        self.res3conv2 = nn.Conv2d(32,32,3,stride=1,padding=1)\n",
    "        self.res3bn2 = nn.BatchNorm2d(32)\n",
    "\n",
    "        self.upsample2 = nn.Upsample(scale_factor=2) #[32,256,256]\n",
    "        self.conv2 = nn.Conv2d(33,16,3,stride=1,padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "\n",
    "        self.res4conv1 = nn.Conv2d(16,16,3,stride=1,padding=1)\n",
    "        self.res4bn1 = nn.BatchNorm2d(16)\n",
    "        self.res4conv2 = nn.Conv2d(16,16,3,stride=1,padding=1)\n",
    "        self.res4bn2 = nn.BatchNorm2d(16)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(16,9,3,stride=1,padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(9)\n",
    "\n",
    "        self.res5conv1 = nn.Conv2d(9,9,3,stride=1,padding=1)\n",
    "        self.res5bn1 = nn.BatchNorm2d(9)\n",
    "        self.res5conv2 = nn.Conv2d(9,9,3,stride=1,padding=1)\n",
    "        self.res5bn2 = nn.BatchNorm2d(9)\n",
    "\n",
    "        self.conv4 = nn.Conv2d(9,1,3,stride=1,padding=1)\n",
    "        # self.bn4 = nn.BatchNorm2d(1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        original_in = F.pad(x, (0,1,0,1), mode='constant', value=-0.5)\n",
    "        x = self.scattering2d(original_in).squeeze(1)\n",
    "        \n",
    "        x = self.conv0(x)\n",
    "        x = F.leaky_relu(self.bn0(x))\n",
    "\n",
    "        resblock1_input =x\n",
    "        x = self.res1conv1(x)\n",
    "        x = F.leaky_relu(self.res1bn1(x))\n",
    "\n",
    "        x = self.res1conv2(x)\n",
    "        x = F.leaky_relu(self.res1bn2(x))\n",
    "\n",
    "        x = x + resblock1_input\n",
    "        resblock2_input = x\n",
    "        x = self.res2conv1(x)\n",
    "\n",
    "        x = self.res2conv2(x)\n",
    "        x = F.leaky_relu(self.res2bn2(x))\n",
    "\n",
    "        x = x + resblock2_input\n",
    "        x = self.upsample1(x)\n",
    "        x = self.conv1(x)\n",
    "        x = F.leaky_relu(self.bn1(x))\n",
    "\n",
    "        resblock3_input = x\n",
    "        x = self.res3conv1(x)\n",
    "        x = F.leaky_relu(self.res3bn1(x))\n",
    "\n",
    "        x = self.res3conv2(x)\n",
    "        x = F.leaky_relu(self.res3bn2(x))\n",
    "        x = x + resblock3_input\n",
    "\n",
    "        x = self.upsample2(x)\n",
    "        x = torch.cat((x, original_in), dim=1)\n",
    "        x = self.conv2(x)\n",
    "        x = F.leaky_relu(self.bn2(x))\n",
    "\n",
    "        resblock4_input = x\n",
    "        x = self.res4conv1(x)\n",
    "        x = F.leaky_relu(self.res4bn1(x))\n",
    "        x = self.res4conv2(x)\n",
    "        x = F.leaky_relu(self.res4bn2(x))\n",
    "        x = x + resblock4_input\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = F.leaky_relu(self.bn3(x))\n",
    "\n",
    "        resblock5_input = x\n",
    "        x = self.res5conv1(x)\n",
    "        x = F.leaky_relu(self.res5bn1(x))\n",
    "        x = self.res5conv2(x)\n",
    "        x = F.leaky_relu(self.res5bn2(x))\n",
    "        x = x + resblock5_input\n",
    "        x = self.conv4(x)\n",
    "        # x = F.sigmoid(x)-0.5\n",
    "        return x[:,:,:-1,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978addf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_dataset= BinaryDenoisingDataset(img,spec)\n",
    "binary_test_dataset = BinaryDenoisingDataset(test_img,test_spec)\n",
    "binary_dataloader = DataLoader(binary_dataset, batch_size=32, shuffle=True)\n",
    "binary_dataloader_test = DataLoader(binary_test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc3c281",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_train(net, trainLoader,testLoader, loss_fn, optimizer, scheduler, NUM_EPOCHS):\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        net.train()\n",
    "        running_loss = 0.0\n",
    "        with tqdm(trainLoader, unit=\"batch\") as tepoch:\n",
    "            for data in tepoch:\n",
    "                tepoch.set_description(f\"Epoch {epoch+1}\")\n",
    "                img_clean,spec_clean, img_noisy, spec_noisy, mask = data\n",
    "                img_noisy = img_noisy.to(device)\n",
    "                img_clean = img_clean.to(device)\n",
    "                spec_noisy = spec_noisy.to(device)\n",
    "                mask = mask.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                denoised = net(img_noisy)\n",
    "                denoised_spec = torch.fft.fft2(denoised)\n",
    "                denoised_spec = fftshift3d(denoised_spec, ifft=False)\n",
    "                spec_mask = mask.type(torch.complex64)\n",
    "                denoised_spec = spec_noisy * spec_mask + denoised_spec * (1 - spec_mask)\n",
    "                outputs = torch.real(torch.fft.ifft2(fftshift3d(denoised_spec, ifft=True)))\n",
    "                loss = loss_fn(outputs, img_clean)\n",
    "                # backpropagation\n",
    "                loss.backward()\n",
    "                # update the parameters\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                tepoch.set_postfix(loss=loss)    \n",
    "            \n",
    "            loss = running_loss / len(trainLoader)\n",
    "            train_loss.append(loss)\n",
    "        scheduler.step()\n",
    "        net.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            with tqdm(testLoader, unit=\"batch\") as tepoch:\n",
    "                for data in tepoch:\n",
    "                    img_clean,spec_clean, img_noisy, spec_noisy, mask = data\n",
    "                    img_noisy = img_noisy.to(device)\n",
    "                    img_clean = img_clean.to(device)\n",
    "                    spec_noisy = spec_noisy.to(device)\n",
    "                    mask = mask.to(device)\n",
    "                    denoised = net(img_noisy)\n",
    "                    denoised_spec = torch.fft.fft2(denoised)\n",
    "                    denoised_spec = fftshift3d(denoised_spec, ifft=False)\n",
    "                    spec_mask = mask.type(torch.complex64)\n",
    "                    denoised_spec = spec_noisy * spec_mask + denoised_spec * (1 - spec_mask)\n",
    "                    outputs = torch.real(torch.fft.ifft2(fftshift3d(denoised_spec, ifft=True)))\n",
    "                    outputs = torch.clamp(outputs, -.5, .5)\n",
    "                    loss = loss_fn(outputs, img_clean)\n",
    "                    val_loss += loss.item()\n",
    "                    tepoch.set_postfix(loss=loss)    \n",
    "                \n",
    "                loss = val_loss / len(testLoader)\n",
    "                test_loss.append(loss)\n",
    "        \n",
    "    \n",
    "    return train_loss,test_loss                          \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ffae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "binaryunet = Unet().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(binaryunet.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "binary_unet_train_loss,binary_unet_test_loss = binary_train(binaryunet, binary_dataloader, binary_dataloader_test, loss_fn, optimizer, scheduler, 25)\n",
    "\n",
    "# corrupted_image, corr_sval, corr_msk = corrupt_data_binary(img[50],spec[50])\n",
    "# plt.imshow(corrupted_image, cmap='gray')\n",
    "# plt.show()\n",
    "# plt.imshow(img[50], cmap='gray')\n",
    "# denoised = binaryunet(corrupted_image)\n",
    "# denoised_spec = torch.fft.fft2(denoised)\n",
    "# denoised_spec = fftshift3d(denoised_spec, ifft=False)\n",
    "# spec_mask = corr_msk.type(torch.complex64)\n",
    "# denoised_spec = corr_sval * spec_mask + denoised_spec * (1 - spec_mask)\n",
    "# output = torch.real(torch.fft.ifft2(fftshift3d(denoised_spec, ifft=True))).clamp(-.5, .5)\n",
    "# plt.imshow(output, cmap='gray')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070399d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(binaryunet.state_dict(), './models/binary_unet_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf80fffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "binarycnndmri = CNNDMRI().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(binarycnndmri.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "binary_cnndmri_train_loss,binary_cnndmri_test_loss = binary_train(binarycnndmri, binary_dataloader, binary_dataloader_test, loss_fn, optimizer, scheduler, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbadf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(binarycnndmri.state_dict(), './models/binary_cnndmri_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44249cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "binarywsta = WSTAutoencoder().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(binarywsta.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "binary_wsta_train_loss,binary_wsta_test_loss = binary_train(binarywsta, binary_dataloader, binary_dataloader_test, loss_fn, optimizer, scheduler, 25)\n",
    "\n",
    "# corrupted_image, corr_sval, corr_msk = corrupt_data_binary(img[50],spec[50])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c867488",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(binarywsta.state_dict(), './models/binary_wsta_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576895f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "rici_dataset = RicianDenoisingDataset(img,spec)\n",
    "rici_test_dataset = RicianDenoisingDataset(test_img,test_spec)\n",
    "rici_dataloader = DataLoader(rici_dataset, batch_size=32, shuffle=True)\n",
    "rici_dataloader_test = DataLoader(rici_test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36512db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ricitrain(net, trainLoader,testLoader, loss_fn, optimizer, scheduler, NUM_EPOCHS):\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        net.train()\n",
    "        running_loss = 0.0\n",
    "        with tqdm(trainLoader, unit=\"batch\") as tepoch:\n",
    "            for data in tepoch:\n",
    "                tepoch.set_description(f\"Epoch {epoch+1}\")\n",
    "                img_clean, img_noisy = data\n",
    "                img_noisy = img_noisy.to(device)\n",
    "                img_clean = img_clean.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(img_noisy)\n",
    "                loss = loss_fn(outputs, img_clean)\n",
    "                # backpropagation\n",
    "                loss.backward()\n",
    "                # update the parameters\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                tepoch.set_postfix(loss=loss)    \n",
    "            \n",
    "            loss = running_loss / len(trainLoader)\n",
    "            train_loss.append(loss)\n",
    "        scheduler.step()\n",
    "        net.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            with tqdm(testLoader, unit=\"batch\") as tepoch:\n",
    "                for data in tepoch:\n",
    "                    img_clean, img_noisy= data\n",
    "                    img_noisy = img_noisy.to(device)\n",
    "                    img_clean = img_clean.to(device)\n",
    "                    outputs = net(img_noisy)\n",
    "                    outputs = torch.clamp(outputs, -.5, .5)\n",
    "                    loss = loss_fn(outputs, img_clean)\n",
    "                    val_loss += loss.item()\n",
    "                    tepoch.set_postfix(loss=loss)    \n",
    "                \n",
    "                loss = val_loss / len(testLoader)\n",
    "                test_loss.append(loss)\n",
    "        \n",
    "    \n",
    "    return train_loss,test_loss         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d579799",
   "metadata": {},
   "outputs": [],
   "source": [
    "ricianunet = Unet().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(ricianunet.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "rici_unet_train_loss,rici_unet_test_loss = ricitrain(ricianunet, rici_dataloader, rici_dataloader_test, loss_fn, optimizer, scheduler, 25)\n",
    "torch.save(ricianunet.state_dict(), './rician_unet_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6248482",
   "metadata": {},
   "outputs": [],
   "source": [
    "ricicnndmri = CNNDMRI().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(ricicnndmri.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "rici_cnndmri_train_loss,rici_cnndmri_test_loss = ricitrain(ricicnndmri, rici_dataloader, rici_dataloader_test, loss_fn, optimizer, scheduler, 25)\n",
    "torch.save(ricicnndmri.state_dict(), './rician_cnndmri_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09771d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "riciwsta = WSTAutoencoder().to(device)\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(riciwsta.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n",
    "rici_wsta_train_loss,rici_wsta_test_loss = ricitrain(riciwsta, rici_dataloader, rici_dataloader_test, loss_fn, optimizer, scheduler, 25)\n",
    "torch.save(riciwsta.state_dict(), './rician_wsta_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a7948d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img[150], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a222d600",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_image, corr_sval, corr_msk = corrupt_data_binary(img[150],spec[150])\n",
    "plt.imshow(corrupted_image, cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "plt.imshow(img[150], cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "corrupted_image =torch.tensor(corrupted_image).unsqueeze(0).unsqueeze(0).to(device)\n",
    "denoised = binarycnndmri(corrupted_image)\n",
    "denoised_spec = torch.fft.fft2(denoised)\n",
    "denoised_spec = fftshift3d(denoised_spec, ifft=False)\n",
    "spec_mask = torch.tensor(corr_msk).unsqueeze(0).unsqueeze(0).type(torch.complex64).to(device)\n",
    "corr_sval = torch.tensor(corr_sval).unsqueeze(0).unsqueeze(0).type(torch.complex64).to(device)\n",
    "denoised_spec = corr_sval * spec_mask + denoised_spec * (1 - spec_mask)\n",
    "output = torch.real(torch.fft.ifft2(fftshift3d(denoised_spec, ifft=True))).clamp(-.5, .5).squeeze(0).squeeze(0)\n",
    "output = output.cpu().detach().numpy()\n",
    "plt.imshow(output, cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a79cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_image, corr_sval, corr_msk = corrupt_data_binary(img[150],spec[150])\n",
    "plt.imshow(corrupted_image, cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "plt.imshow(img[150], cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "corrupted_image =torch.tensor(corrupted_image).unsqueeze(0).unsqueeze(0).to(device)\n",
    "denoised = binaryunet(corrupted_image)\n",
    "denoised_spec = torch.fft.fft2(denoised)\n",
    "denoised_spec = fftshift3d(denoised_spec, ifft=False)\n",
    "spec_mask = torch.tensor(corr_msk).unsqueeze(0).unsqueeze(0).type(torch.complex64).to(device)\n",
    "corr_sval = torch.tensor(corr_sval).unsqueeze(0).unsqueeze(0).type(torch.complex64).to(device)\n",
    "denoised_spec = corr_sval * spec_mask + denoised_spec * (1 - spec_mask)\n",
    "output = torch.real(torch.fft.ifft2(fftshift3d(denoised_spec, ifft=True))).clamp(-.5, .5).squeeze(0).squeeze(0)\n",
    "output = output.cpu().detach().numpy()\n",
    "plt.imshow(output, cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccac8b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_image, corr_sval, corr_msk = corrupt_data_binary(img[150],spec[150])\n",
    "plt.imshow(corrupted_image, cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "plt.imshow(img[150], cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "corrupted_image =torch.tensor(corrupted_image).unsqueeze(0).unsqueeze(0).to(device)\n",
    "denoised = binarywsta(corrupted_image)\n",
    "denoised_spec = torch.fft.fft2(denoised)\n",
    "denoised_spec = fftshift3d(denoised_spec, ifft=False)\n",
    "spec_mask = torch.tensor(corr_msk).unsqueeze(0).unsqueeze(0).type(torch.complex64).to(device)\n",
    "corr_sval = torch.tensor(corr_sval).unsqueeze(0).unsqueeze(0).type(torch.complex64).to(device)\n",
    "denoised_spec = corr_sval * spec_mask + denoised_spec * (1 - spec_mask)\n",
    "output = torch.real(torch.fft.ifft2(fftshift3d(denoised_spec, ifft=True))).clamp(-.5, .5).squeeze(0).squeeze(0)\n",
    "output = output.cpu().detach().numpy()\n",
    "plt.imshow(output, cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310619ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_image = corrupt_data_rician(img[150]+0.5,11).clip(0,1)-0.5\n",
    "plt.imshow(corrupted_image, cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "plt.imshow(img[150], cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "corrupted_image =torch.tensor(corrupted_image).unsqueeze(0).unsqueeze(0).to(device)\n",
    "output = ricianunet(corrupted_image.float()).clamp(-.5, .5).squeeze(0).squeeze(0)\n",
    "output = output.cpu().detach().numpy()\n",
    "plt.imshow(output, cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4686fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_image = corrupt_data_rician(img[150]+0.5,11).clip(0,1)-0.5\n",
    "plt.imshow(corrupted_image, cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "plt.imshow(img[150], cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "corrupted_image =torch.tensor(corrupted_image).unsqueeze(0).unsqueeze(0).to(device)\n",
    "output = ricicnndmri(corrupted_image.float()).clamp(-.5, .5).squeeze(0).squeeze(0)\n",
    "output = output.cpu().detach().numpy()\n",
    "plt.imshow(output, cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c6a4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_image = corrupt_data_rician(img[150]+0.5,11).clip(0,1)-0.5\n",
    "plt.imshow(corrupted_image, cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "plt.imshow(img[150], cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "corrupted_image =torch.tensor(corrupted_image).unsqueeze(0).unsqueeze(0).to(device)\n",
    "output = riciwsta(corrupted_image.float()).clamp(-.5, .5).squeeze(0).squeeze(0)\n",
    "output = output.cpu().detach().numpy()\n",
    "plt.imshow(output, cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0844c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrupted_image, corr_sval, corr_msk = corrupt_data_binary(img[150],spec[150])\n",
    "plt.imshow(corrupted_image, cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "plt.imshow(img[50], cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "corrupted_image =torch.tensor(corrupted_image).unsqueeze(0).unsqueeze(0).to(device)\n",
    "denoised = model(corrupted_image)\n",
    "denoised_spec = torch.fft.fft2(denoised)\n",
    "denoised_spec = fftshift3d(denoised_spec, ifft=False)\n",
    "spec_mask = torch.tensor(corr_msk).unsqueeze(0).unsqueeze(0).type(torch.complex64).to(device)\n",
    "corr_sval = torch.tensor(corr_sval).unsqueeze(0).unsqueeze(0).type(torch.complex64).to(device)\n",
    "denoised_spec = corr_sval * spec_mask + denoised_spec * (1 - spec_mask)\n",
    "output = torch.real(torch.fft.ifft2(fftshift3d(denoised_spec, ifft=True))).clamp(-.5, .5).squeeze(0).squeeze(0)\n",
    "output = output.cpu().detach().numpy()\n",
    "plt.imshow(output, cmap='gray')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
