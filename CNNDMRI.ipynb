{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdbe1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "from torchsummary import summary\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "import nibabel as nib\n",
    "from scipy.fftpack import fft, ifft, fft2, ifft2, fftshift, ifftshift\n",
    "import PIL.Image\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7887f287",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9c17fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pkl(filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        return pickle.load(file)\n",
    "def fftshift2d(x, ifft=False):\n",
    "    assert (len(x.shape) == 2) and all([(s % 2 == 1) for s in x.shape])\n",
    "    s0 = (x.shape[0] // 2) + (0 if ifft else 1)\n",
    "    s1 = (x.shape[1] // 2) + (0 if ifft else 1)\n",
    "    x = np.concatenate([x[s0:, :], x[:s0, :]], axis=0)\n",
    "    x = np.concatenate([x[:, s1:], x[:, :s1]], axis=1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a0bef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruta = \"C:/Users/javit/Desktop/MRI datasets/datasets/ixi_train-001.pkl\"\n",
    "# ruta_test = \"C:/Users/javit/Desktop/MRI datasets/datasets/ixi_valid.pkl\"\n",
    "ruta = \"C:/Users/javit/Desktop/N2N/datasets/ixi_train.pkl\"\n",
    "ruta_test = \"C:/Users/javit/Desktop/N2N/datasets/ixi_valid.pkl\"\n",
    "img, spec = load_pkl(ruta)\n",
    "img=img[:,:-1,:-1] #images are now 255,255\n",
    "img = img.astype(np.float32) / 255.0 - 0.5 # normalize and make sure they are in range [-.5,.5]\n",
    "test_img, test_spec = load_pkl(ruta_test)\n",
    "test_img=test_img[:,:-1,:-1]\n",
    "test_img=test_img.astype(np.float32) / 255.0 - 0.5\n",
    "\n",
    "\n",
    "p_at_edge=0.025\n",
    "h = [s // 2 for s in (255,255)] #255\n",
    "r = [np.arange(s, dtype=np.float32) - h for s, h in zip((255,255), h)]\n",
    "r = [x ** 2 for x in r]\n",
    "r = (r[0][:, np.newaxis] + r[1][np.newaxis, :]) ** .5\n",
    "m = (p_at_edge ** (1./h[1])) ** r\n",
    "bern_mask = m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1adb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt_data(img, spec):\n",
    "    global bern_mask\n",
    "    mask = bern_mask\n",
    "    # print('Bernoulli probability at edge = %.5f' % mask[h[0], 0])\n",
    "    # print('Average Bernoulli probability = %.5f' % np.mean(mask))\n",
    "    keep = (np.random.uniform(0.0, 1.0, size=spec.shape)**2 < mask)\n",
    "    keep = keep & keep[::-1, ::-1]\n",
    "    sval = spec * keep\n",
    "    smsk = keep.astype(np.float32)\n",
    "    spec = fftshift2d(sval / (mask + ~keep), ifft=True) # Add 1.0 to not-kept values to prevent div-by-zero.\n",
    "    img = np.real(np.fft.ifft2(spec)).astype(np.float32)\n",
    "    return img, sval, smsk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479d9516",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIDenoisingDataset(Dataset):\n",
    "    def __init__(self,clean_images,clean_specs,t=64,corrupt_fn=corrupt_data,augment_fn=None):\n",
    "        super(MRIDenoisingDataset, self).__init__()\n",
    "        self.clean_images = clean_images\n",
    "        self.clean_specs = clean_specs\n",
    "        self.t = t\n",
    "        self.corrupt_fn = corrupt_fn\n",
    "        self.augment_fn = augment_fn\n",
    "    def __len__(self):\n",
    "        return len(self.clean_images)\n",
    "    def __getitem__(self, idx):\n",
    "        img_clean= self.clean_images[idx]\n",
    "        spec_clean = self.clean_specs[idx]\n",
    "        # Data augmentation\n",
    "        if self.augment_fn:\n",
    "            img_clean,spec_clean = self.augment_fn(img_clean,spec_clean,t=self.t)        \n",
    "        # Corrupt data\n",
    "        cimg, cspec, cmask = self.corrupt_fn(img_clean,spec_clean)\n",
    "        img_noisy = torch.tensor(cimg,dtype=torch.float32)\n",
    "        spec_noisy = torch.tensor(cspec,dtype=torch.complex64)\n",
    "        mask = torch.tensor(cmask,dtype=torch.float32)\n",
    "        img_clean = torch.tensor(img_clean,dtype=torch.float32)\n",
    "        spec_clean = torch.tensor(spec_clean,dtype=torch.complex64)\n",
    "        return img_clean.unsqueeze(0), spec_clean.unsqueeze(0), img_noisy.unsqueeze(0), spec_noisy.unsqueeze(0), mask.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e35f78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset= MRIDenoisingDataset(img,spec)\n",
    "test_dataset = MRIDenoisingDataset(test_img,test_spec)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "dataloader_test = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7be411",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdea677",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutorEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutorEncoder, self).__init__()\n",
    "\n",
    "        #Initial convolutions\n",
    "        self.conv1 = nn.Conv2d(1,64,kernel_size=3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(64,64,kernel_size=3,padding=1)\n",
    "\n",
    "        # Encoder layers\n",
    "        self.enc1 = nn.Conv2d(64, 128, kernel_size=3, padding=1, stride=2)\n",
    "        self.enc2 = nn.Conv2d(128, 128, kernel_size=3, padding=1, stride=2)\n",
    "\n",
    "        #Residual blocks\n",
    "        self.res1conv1 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.res1conv2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.res2conv1 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.res2conv2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.res3conv1 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.res3conv2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "        self.res4conv1 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn7 = nn.BatchNorm2d(128)\n",
    "        self.res4conv2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn8 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # Decoder layers\n",
    "        self.dec1 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2,padding=1,output_padding=1)\n",
    "        self.dec2 = nn.ConvTranspose2d(64, 64, kernel_size=3, stride=2,padding=1)\n",
    "\n",
    "        #Final convolution\n",
    "        self.out = nn.Conv2d(64, 1, kernel_size=3, padding=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        original_noisy = x\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        #Encoder\n",
    "        x = F.relu(self.enc1(x))\n",
    "        x = F.relu(self.enc2(x))\n",
    "        #Residual blocks\n",
    "        res1 = x\n",
    "        x = self.res1conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.res1conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x += res1\n",
    "\n",
    "        res2 = x\n",
    "        x = self.res2conv1(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.res2conv2(x)\n",
    "        x = self.bn4(x)\n",
    "        x += res2\n",
    "\n",
    "        res3 = x\n",
    "        x = self.res3conv1(x)\n",
    "        x = F.relu(self.bn5(x))\n",
    "        x = self.res3conv2(x)\n",
    "        x = self.bn6(x)\n",
    "        x += res3\n",
    "\n",
    "        res4 = x\n",
    "        x = self.res4conv1(x)\n",
    "        x = F.relu(self.bn7(x))\n",
    "        x = self.res4conv2(x)\n",
    "        x = self.bn8(x)\n",
    "        x += res4\n",
    "        # Decoder\n",
    "        x = F.relu(self.dec1(x))\n",
    "        x = F.relu(self.dec2(x))\n",
    "        #Final convolution\n",
    "        x = self.out(x)\n",
    "        x += original_noisy\n",
    "        return x\n",
    "\n",
    "model = AutorEncoder().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da315237",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b54251",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(model, (1, 255, 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f126261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss function\n",
    "loss_fn = nn.MSELoss()\n",
    "# the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=25, eta_min=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e513e328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fftshift3d(x, ifft):\n",
    "    assert len(x.shape) == 3\n",
    "    s0 = (x.shape[1] // 2) + (0 if ifft else 1)\n",
    "    s1 = (x.shape[2] // 2) + (0 if ifft else 1)\n",
    "    x = torch.cat([x[:, s0:, :], x[:, :s0, :]], dim=1)\n",
    "    x = torch.cat([x[:, :, s1:], x[:, :, :s1]], dim=2)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14af3e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, trainLoader,testLoader, NUM_EPOCHS):\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        running_loss = 0.0\n",
    "        with tqdm(trainLoader, unit=\"batch\") as tepoch:\n",
    "            for data in tepoch:\n",
    "                tepoch.set_description(f\"Epoch {epoch+1}\")\n",
    "                img_clean,spec_clean, img_noisy, spec_noisy, mask = data\n",
    "                img_noisy = img_noisy.to(device)\n",
    "                img_clean = img_clean.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = net(img_noisy)\n",
    "                loss = loss_fn(outputs, img_clean)\n",
    "                # backpropagation\n",
    "                loss.backward()\n",
    "                # update the parameters\n",
    "                optimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                tepoch.set_postfix(loss=loss)    \n",
    "            \n",
    "            loss = running_loss / len(trainLoader)\n",
    "            train_loss.append(loss)\n",
    "        scheduler.step()\n",
    "        net.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            with tqdm(testLoader, unit=\"batch\") as tepoch:\n",
    "                for data in tepoch:\n",
    "                    img_clean,spec_clean, img_noisy, spec_noisy, mask = data\n",
    "                    img_noisy = img_noisy.to(device)\n",
    "                    img_clean = img_clean.to(device)\n",
    "                    outputs = net(img_noisy)\n",
    "                    outputs = torch.clamp(outputs, -.5, .5)\n",
    "                    loss = loss_fn(outputs, img_clean)\n",
    "                    val_loss += loss.item()\n",
    "                    tepoch.set_postfix(loss=loss)    \n",
    "                \n",
    "                loss = val_loss / len(testLoader)\n",
    "                test_loss.append(loss)\n",
    "        \n",
    "    \n",
    "    return train_loss,test_loss                          \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fd0475",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss,test_loss = train(model, dataloader, dataloader_test, 25)\n",
    "plt.figure()\n",
    "plt.plot(train_loss, label='train loss')\n",
    "plt.plot(test_loss, label='test loss')\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762ec155",
   "metadata": {},
   "outputs": [],
   "source": [
    "10*np.log10(1/ 0.0013)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9f1b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img[50],cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b61ba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_noisy, spec_noisy, mask = corrupt_data(img[50], spec[50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce885186",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.clip(img_noisy, -.5, .5),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e740c376",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_noisy=np.clip(img_noisy, -.5, .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744dcb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_noisy = torch.tensor(img_noisy).to(device)\n",
    "img_noisy = img_noisy.unsqueeze(0).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f9d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed = model(img_noisy.to(device))\n",
    "reconstructed=torch.clamp(reconstructed, -0.5, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0844de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63fd2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.squeeze(reconstructed.cpu().detach().numpy()),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abb4b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean((img[50] - np.squeeze(reconstructed.cpu().detach().numpy()))**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f5f5b4",
   "metadata": {},
   "source": [
    "## Let's try rician noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875674eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rician_noise(img,noise_percent):\n",
    "    sigma =(noise_percent/100)*img.max().item()\n",
    "    noise1 = np.random.normal(0,sigma,img.shape)\n",
    "    noise2 = np.random.normal(0,sigma,img.shape)\n",
    "    noisy_img = np.sqrt((img+noise1)**2+noise2**2)\n",
    "    return noisy_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defd9620",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RicianMRIDenoisingDataset(Dataset):\n",
    "    def __init__(self,clean_images,t=64,corrupt_fn=rician_noise,augment_fn=None):\n",
    "        super(RicianMRIDenoisingDataset, self).__init__()\n",
    "        self.clean_images = clean_images\n",
    "        self.t = t\n",
    "        self.corrupt_fn = corrupt_fn\n",
    "        self.augment_fn = augment_fn\n",
    "    def __len__(self):\n",
    "        return len(self.clean_images)\n",
    "    def __getitem__(self, idx):\n",
    "        img_clean= self.clean_images[idx]+0.5 #now img in[0,1] range\n",
    "        # Data augmentation\n",
    "        if self.augment_fn:\n",
    "            img_clean,spec_clean = self.augment_fn(img_clean,spec_clean,t=self.t)        \n",
    "        # Corrupt data\n",
    "        cimg = self.corrupt_fn(img_clean,11)\n",
    "        img_noisy = torch.tensor(cimg,dtype=torch.float32).clamp(0,1)\n",
    "        img_clean = torch.tensor(img_clean,dtype=torch.float32).clamp(0,1)\n",
    "        return img_clean.unsqueeze(0), img_noisy.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458c406f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Riciandataset= RicianMRIDenoisingDataset(img,spec)\n",
    "Riciantest_dataset = RicianMRIDenoisingDataset(test_img,test_spec)\n",
    "Riciandataloader = DataLoader(Riciandataset, batch_size=32, shuffle=True)\n",
    "Riciandataloader_test = DataLoader(Riciantest_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b25fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_im = rician_noise(img[100]+0.5,11)\n",
    "plt.imshow(np.clip(noisy_im,0,1),cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5b3eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse=np.mean(img[100]+0.5-np.clip(noisy_im,0,1))**2\n",
    "psnr=10*np.log10(1/mse)\n",
    "psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e92ddf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img[200]+0.5,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1a6a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd85927",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RicciAutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RicciAutoEncoder, self).__init__()\n",
    "\n",
    "        #Initial convolutions\n",
    "        self.conv1 = nn.Conv2d(1,64,kernel_size=3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(64,64,kernel_size=3,padding=1)\n",
    "\n",
    "        # Encoder layers\n",
    "        self.enc1 = nn.Conv2d(64, 128, kernel_size=3, padding=1, stride=2)\n",
    "        self.enc2 = nn.Conv2d(128, 128, kernel_size=3, padding=1, stride=2)\n",
    "\n",
    "        #Residual blocks\n",
    "        self.res1conv1 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(128)\n",
    "        self.res1conv2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        self.res2conv1 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm2d(128)\n",
    "        self.res2conv2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn4 = nn.BatchNorm2d(128)\n",
    "        self.res3conv1 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        self.res3conv2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn6 = nn.BatchNorm2d(128)\n",
    "        self.res4conv1 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn7 = nn.BatchNorm2d(128)\n",
    "        self.res4conv2 = nn.Conv2d(128, 128, kernel_size=3, padding=1)\n",
    "        self.bn8 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # Decoder layers\n",
    "        self.dec1 = nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2,padding=1,output_padding=1)\n",
    "        self.dec2 = nn.ConvTranspose2d(64, 64, kernel_size=3, stride=2,padding=1)\n",
    "\n",
    "        #Final convolution\n",
    "        self.out = nn.Conv2d(64, 1, kernel_size=3, padding=1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        original_noisy = x\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        #Encoder\n",
    "        x = F.relu(self.enc1(x))\n",
    "        x = F.relu(self.enc2(x))\n",
    "        #Residual blocks\n",
    "        res1 = x\n",
    "        x = self.res1conv1(x)\n",
    "        x = F.relu(self.bn1(x))\n",
    "        x = self.res1conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x += res1\n",
    "\n",
    "        res2 = x\n",
    "        x = self.res2conv1(x)\n",
    "        x = F.relu(self.bn3(x))\n",
    "        x = self.res2conv2(x)\n",
    "        x = self.bn4(x)\n",
    "        x += res2\n",
    "\n",
    "        res3 = x\n",
    "        x = self.res3conv1(x)\n",
    "        x = F.relu(self.bn5(x))\n",
    "        x = self.res3conv2(x)\n",
    "        x = self.bn6(x)\n",
    "        x += res3\n",
    "\n",
    "        res4 = x\n",
    "        x = self.res4conv1(x)\n",
    "        x = F.relu(self.bn7(x))\n",
    "        x = self.res4conv2(x)\n",
    "        x = self.bn8(x)\n",
    "        x += res4\n",
    "        # Decoder\n",
    "        x = F.relu(self.dec1(x))\n",
    "        x = F.relu(self.dec2(x))\n",
    "        #Final convolution\n",
    "        x = self.out(x)\n",
    "        x += original_noisy\n",
    "        return x\n",
    "\n",
    "Riccimodel = RicciAutoEncoder().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc71ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the loss function\n",
    "Riciloss_fn = nn.MSELoss()\n",
    "# the optimizer\n",
    "Ricioptimizer = optim.Adam(Riccimodel.parameters(), lr=0.001)\n",
    "Ricischeduler = CosineAnnealingLR(Ricioptimizer, T_max=25, eta_min=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f35249a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Riccitrain(net, trainLoader,testLoader, NUM_EPOCHS):\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        running_loss = 0.0\n",
    "        with tqdm(trainLoader, unit=\"batch\") as tepoch:\n",
    "            for data in tepoch:\n",
    "                tepoch.set_description(f\"Epoch {epoch+1}\")\n",
    "                img_clean, img_noisy= data\n",
    "                img_noisy = img_noisy.to(device)\n",
    "                img_clean = img_clean.to(device)\n",
    "                Ricioptimizer.zero_grad()\n",
    "                outputs = net(img_noisy)\n",
    "                loss = Riciloss_fn(outputs, img_clean)\n",
    "                # backpropagation\n",
    "                loss.backward()\n",
    "                # update the parameters\n",
    "                Ricioptimizer.step()\n",
    "                running_loss += loss.item()\n",
    "                tepoch.set_postfix(loss=loss)    \n",
    "            \n",
    "            loss = running_loss / len(trainLoader)\n",
    "            train_loss.append(loss)\n",
    "        Ricischeduler.step()\n",
    "        net.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            with tqdm(testLoader, unit=\"batch\") as tepoch:\n",
    "                for data in tepoch:\n",
    "                    img_clean,img_noisy = data\n",
    "                    img_noisy = img_noisy.to(device)\n",
    "                    img_clean = img_clean.to(device)\n",
    "                    outputs = net(img_noisy)\n",
    "                    outputs = torch.clamp(outputs, -0.5, 0.5)\n",
    "                    loss = Riciloss_fn(outputs, img_clean)\n",
    "                    val_loss += loss.item()\n",
    "                    tepoch.set_postfix(loss=loss)    \n",
    "                \n",
    "                loss = val_loss / len(testLoader)\n",
    "                test_loss.append(loss)\n",
    "    \n",
    "    return train_loss,test_loss                          \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37933e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss,test_loss = Riccitrain(Riccimodel, Riciandataloader, Riciandataloader_test, 25)\n",
    "plt.figure()\n",
    "plt.plot(train_loss, label='train loss')\n",
    "plt.plot(test_loss, label='test loss')\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd74856",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(train_loss, label='train loss')\n",
    "plt.plot(test_loss, label='test loss')\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d8b27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy = rician_noise(img[150]+0.5,11)\n",
    "reconstructed = Riccimodel(torch.tensor(noisy,dtype=torch.float).unsqueeze(0).unsqueeze(0).to(device))\n",
    "reconstructed=torch.clamp(reconstructed, 0, 1)\n",
    "plt.imshow(np.squeeze(reconstructed.cpu().detach().numpy()),cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538f0a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(noisy,cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
